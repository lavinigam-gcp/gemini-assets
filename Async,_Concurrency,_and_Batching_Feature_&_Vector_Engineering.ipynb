{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCIMTPB1WoTq"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVV6txOmNMn"
      },
      "source": [
        "# Async, Concurrency, and Batching: Feature & Vector Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718e8c79-afd9-41ac-ec51-c8b81f123fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/5.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform\n",
        "! pip3 install --upgrade --user --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "BUCKET_NAME = \"mlops-for-genai\" # @param {type:\"string\"}\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Initialize cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bucket = storage_client.bucket(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c1f770-03c9-4244-f044-18bce3ed5c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import pandas as pd\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        ")\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from rich.markdown import Markdown as rich_Markdown\n",
        "from rich import print as rich_print\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "from collections import Counter\n",
        "import PyPDF2\n",
        "import io\n",
        "from io import BytesIO\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import concurrent.futures\n",
        "import random, string\n",
        "import asyncio\n",
        "import time\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "import psutil\n",
        "import asyncio.locks\n",
        "import os\n",
        "import json\n",
        "import aiohttp\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "### Load the models\n",
        "\n",
        "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U7ExWmuLBdIA"
      },
      "outputs": [],
      "source": [
        "MODEL_ID_PRO = \"gemini-1.5-pro-001\"  # @param {type:\"string\"}\n",
        "MODEL_ID_FLASH = \"gemini-1.5-flash-001\" # @param {type:\"string\"}\n",
        "\n",
        "model_pro = GenerativeModel(MODEL_ID_PRO)\n",
        "model_flash = GenerativeModel(MODEL_ID_FLASH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add data path"
      ],
      "metadata": {
        "id": "ff0p6xaCteKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prototype_data = \"multimodal-finanace-qa/data/unstructured/prototype/\"  # @param {type:\"string\"}\n",
        "production_data = \"multimodal-finanace-qa/data/unstructured/production/\"  # @param {type:\"string\"}\n",
        "image_output_path = \"multimodal-finanace-qa/data/unstructured/temp/img\"  # @param {type:\"string\"}\n",
        "embedding_input_path = \"multimodal-finanace-qa/data/embeddings\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "7NdP_n5ttejN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acRxKRA-sr0j"
      },
      "source": [
        "## Feature Engineeing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building features from PDFs"
      ],
      "metadata": {
        "id": "rA-02L4nuehR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting page wise text and images from the documents"
      ],
      "metadata": {
        "id": "2dvvdxOh_Lck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Features from PDF Files - Text"
      ],
      "metadata": {
        "id": "2xRQ-ywgZdWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomword(length):\n",
        "   letters = string.ascii_lowercase\n",
        "   return ''.join(random.choice(letters) for i in range(length))\n",
        "\n",
        "\n",
        "def upload_gcs_image_file(bucket_object, image_gcs_path, img_bytes):\n",
        "    \"\"\"Uploads a file to the bucket and returns the full GCS URI.\"\"\"\n",
        "    blob = bucket_object.blob(image_gcs_path)\n",
        "    blob.upload_from_string(img_bytes)\n",
        "\n",
        "    # Construct the full GCS URI\n",
        "    gcs_uri = f\"gs://{bucket_object.name}/{image_gcs_path}\"\n",
        "\n",
        "    # print(f\"Image file uploaded to: {gcs_uri}\")\n",
        "    return gcs_uri\n",
        "\n",
        "\n",
        "def extract_image_metadata(xObject,filename,page_num, image_output_path,bucket_object, upload_image_to_gcs=False):\n",
        "    image_metadata = []\n",
        "    for image_number, obj in enumerate(xObject):\n",
        "        if xObject[obj]['/Subtype'] == '/Image':\n",
        "            image_available = True\n",
        "            # Explicitly handle desired formats\n",
        "            if not xObject[obj].get('/Filter') == '/FlateDecode':\n",
        "              try:\n",
        "                  img = Image.open(BytesIO(xObject[obj]._data))\n",
        "                  # if img.format.upper() in ['JPEG', 'PNG', 'TIFF']:\n",
        "                  img_bytes = io.BytesIO()\n",
        "                  img.save(img_bytes, format=img.format)\n",
        "                  img_bytes = img_bytes.getvalue()\n",
        "\n",
        "                  image_name = f\"{filename.replace(' ', '_').lower().split('.')[0]}_page{page_num+1}_{randomword(6)}.{img.format.lower()}\"\n",
        "                  # image_gcs_path = f\"gs://{image_output_path}/{image_name}\"\n",
        "                  image_gcs_path = image_output_path+f\"/{image_name}\"\n",
        "                  image_size = img.size\n",
        "                  # print(f\"Saving image to: {image_gcs_path}\")\n",
        "                  # if upload_image_to_gcs:\n",
        "                  if upload_image_to_gcs:\n",
        "                    image_gcs_path_final = upload_gcs_image_file(bucket_object, image_gcs_path, img_bytes)\n",
        "                  else:\n",
        "                    image_gcs_path_final = None\n",
        "                  image_metadata.append({\n",
        "                      'image_available': image_available,\n",
        "                      'image_counter': int(image_number+1),\n",
        "                      'image_gcs_path': image_gcs_path_final,\n",
        "                      'image_size': image_size\n",
        "                  })\n",
        "                  # else:\n",
        "                  #     print(f\"Unsupported image format: {img.format}\")\n",
        "                  #     continue\n",
        "              except Exception as e:\n",
        "                print(\"Error: \", e)\n",
        "                print(\"Error for image in file: \", filename, \"and page number: \",page_num + 1,\n",
        "                      \" with gcs path: \", f\"gs://{blob.bucket.name}/{blob.name}\")\n",
        "                print(f\"Error: Unable to identify image format.\")\n",
        "                print(f\"Image Subtype: {xObject[obj]['/Subtype']}\")\n",
        "                print(f\"Image Filter: {xObject[obj].get('/Filter', 'None')}\")\n",
        "                print(\"Skipping this. Debug this. \")\n",
        "                # print(\"Error: \", e)\n",
        "                continue\n",
        "    return image_metadata\n",
        "\n",
        "def extract_pdf_data(blob, image_output_path, upload_image_to_gcs=False, bucket_object=None):\n",
        "  \"\"\"Extracts text and images from a PDF blob and returns metadata.\"\"\"\n",
        "  pdf_content = BytesIO(blob.download_as_bytes())\n",
        "  try:\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_content)\n",
        "    pdf_data = []\n",
        "    # pdf_type = \"/\".join(blob.name.split(\"/\")[1:-1])\n",
        "    pdf_type = blob.name.split(\"/\")[-2]\n",
        "    filename = blob.name.split(\"/\")[-1]\n",
        "    # print(\"filename: \", filename)\n",
        "\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "      page = pdf_reader.pages[page_num]\n",
        "      text = page.extract_text()\n",
        "      image_available = False\n",
        "      image_gcs_path = None\n",
        "      image_size = None\n",
        "\n",
        "      page_metadata = {\n",
        "          'text_type' : pdf_type,\n",
        "          'file_name': filename,\n",
        "          'gcs_path': \"gs://\"+blob.bucket.name+\"/\"+blob.name,\n",
        "          'page_number': page_num+1,\n",
        "          'text': text if text else None,\n",
        "          'image_available': False,\n",
        "          'image_counter': None,\n",
        "          'image_gcs_path': None,\n",
        "          'image_size': None\n",
        "      }\n",
        "\n",
        "      if '/XObject' in page['/Resources']:\n",
        "        xObject = page['/Resources']['/XObject'].get_object()\n",
        "        image_metadata = extract_image_metadata(xObject,filename,page_num, image_output_path,bucket_object, upload_image_to_gcs)\n",
        "        for metadata in image_metadata:\n",
        "          page_metadata = {\n",
        "              'text_type' : pdf_type,\n",
        "              'file_name': filename,\n",
        "              'gcs_path': \"gs://\"+blob.bucket.name+\"/\"+blob.name,\n",
        "              'page_number': page_num+1,\n",
        "              'text': text if text else None,\n",
        "              'image_available': metadata['image_available'],\n",
        "              'image_counter': int(metadata['image_counter']),\n",
        "              'image_gcs_path': metadata['image_gcs_path'],\n",
        "              'image_size': metadata['image_size']\n",
        "          }\n",
        "\n",
        "          pdf_data.append(page_metadata)\n",
        "      else:\n",
        "        pdf_data.append(page_metadata)\n",
        "\n",
        "    return pdf_data\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Warning: Could not read PDF file '{blob.name}' (might be encrypted or corrupted). Error: {e}\")\n",
        "    return []\n",
        "\n",
        "def get_text_from_pdf(bucket_object, prefix='', image_output_path=None,upload_image_to_gcs=False,extract_tables=False):\n",
        "  \"\"\"Extracts text and images from PDFs in a GCS bucket, processes in parallel.\"\"\"\n",
        "\n",
        "  all_pdf_data = []\n",
        "  with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    futures = []\n",
        "    for blob in bucket_object.list_blobs(prefix=prefix):\n",
        "      if blob.name.lower().endswith('.pdf'):\n",
        "        # print(blob.name)\n",
        "        futures.append(executor.submit(extract_pdf_data, blob, image_output_path,\n",
        "                                       upload_image_to_gcs, bucket_object))\n",
        "\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "      all_pdf_data.extend(future.result())\n",
        "\n",
        "  return pd.DataFrame(all_pdf_data)"
      ],
      "metadata": {
        "id": "1JHp5NXuIFIT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pdf_metadata_flash = get_text_from_pdf(bucket, prefix=production_data,\n",
        "                       image_output_path=image_output_path,\n",
        "                       upload_image_to_gcs=True,\n",
        "                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeWuOF3BvMOg",
        "outputId": "63d1f88e-8d36-4149-8b4d-5bf2be4a6a17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  cannot identify image file <_io.BytesIO object at 0x7e02bcfd2930>\n",
            "Warning: Could not read PDF file 'multimodal-finanace-qa/data/unstructured/production/reports/2020/annual_report/2020-alphabet-annual-report.pdf' (might be encrypted or corrupted). Error: name 'blob' is not defined\n",
            "CPU times: user 2min 51s, sys: 2.58 s, total: 2min 53s\n",
            "Wall time: 2min 57s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_metadata_flash.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaKDzgI2yulm",
        "outputId": "7722e93e-2fc3-4479-c80b-54bf9a4249b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1549, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_metadata_flash.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "PY9yEyKsv97_",
        "outputId": "b31f64e2-e92c-4792-a74d-62bd211f3e4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  text_type                                          file_name  \\\n",
              "0  blogpost   Google announces the Coalition for Secure AI.pdf   \n",
              "1  blogpost  Google Gemini updates_ Flash 1.5, Gemma 2 and ...   \n",
              "\n",
              "                                            gcs_path  page_number  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "\n",
              "                                                text  image_available  \\\n",
              "0  Additionally, CoSAI will collaborate with orga...            False   \n",
              "1  1.5 Pro can now follow increasingly complex an...            False   \n",
              "\n",
              "   image_counter image_gcs_path image_size  \n",
              "0            NaN           None       None  \n",
              "1            NaN           None       None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9c92c03-4c4d-4923-a02b-6b6a10ee183f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google announces the Coalition for Secure AI.pdf</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Additionally, CoSAI will collaborate with orga...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google Gemini updates_ Flash 1.5, Gemma 2 and ...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.5 Pro can now follow increasingly complex an...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9c92c03-4c4d-4923-a02b-6b6a10ee183f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9c92c03-4c4d-4923-a02b-6b6a10ee183f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9c92c03-4c4d-4923-a02b-6b6a10ee183f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1a89a52-f72f-4ef3-a750-c328fd4fc865\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1a89a52-f72f-4ef3-a750-c328fd4fc865')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1a89a52-f72f-4ef3-a750-c328fd4fc865 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pdf_metadata_flash",
              "summary": "{\n  \"name\": \"pdf_metadata_flash\",\n  \"rows\": 1549,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"earning_transcript\",\n          \"annual_report\",\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"20221025-alphabet-10q.pdf\",\n          \"20210203-alphabet-10k.pdf\",\n          \"2021_Q4_Earnings_Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/quaterly_report/20221025-alphabet-10q.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2020/quaterly_report/20210203-alphabet-10k.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2021/earning_transcript/2021_Q4_Earnings_Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": 1,\n        \"max\": 136,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          74,\n          46,\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1472,\n        \"samples\": [\n          \"development , resources to support their financial health, and access to excellent healthcare choices. Our competitive \\ncompensation programs help us to attract and retain top candidates, and we will continue to invest in recruiting \\ntalented people to technical and non-technical roles,  and rewarding them well. We provide a variety of high quality \\ntraining and support to our managers to build and strengthen their capabilities- \\u2013ranging from courses for new \\nmanagers, to learning resources that help them provide feedback and manage performance, to coaching and \\nindividual support.\\nAt Alphabet , we are committed to making diversity, equity, and inclusion part of everything we do and to growing a \\nworkforce that is representative of the users we serve. More information on Google\\u2019s approach to diversity can be \\nfound in our annual diversity reports, available publicly at diversity.google. The contents of our diversity reports are not \\nincorporated by reference into this Annual Report on Form 10-K or in any other report or document we file with the \\nSEC.\\n As of December 31, 2021 , Alphabet had 156,500  employees. We have work councils and statutory employee \\nrepresentation obligations in certain countries, and we are committed to supporting protected labor rights, maintaining \\nan open culture and listening to all employees. Supporting healthy and open dialogue is central to how we work, and \\nwe communicate information about the company through multiple internal channels to our employees.   \\nWhen necessary, we contract with businesses around the world to provide specialized services where we do not \\nhave appropriate in-house expertise or resources, often in fields that require specialized training like cafe operations,  \\ncontent moderation, customer support, and physical security. We also contract with temporary staffing agencies when \\nwe need to cover short-term leaves, when we have spikes in business needs, or when we need to quickly incubate \\nspecial projects. We choose our partners and staffing agencies carefully, and review their compliance with Google\\u2019s \\nSupplier Code of Conduct.  We continually make improvements to promote a respectful and positive working \\nenvironment for everyone \\u2014 employees, vendors, and temporary staff alike.\\nGovernment Regulation\\nWe are subject to numerous United States (U.S.) federal, state, and foreign laws and regulations covering a wide \\nvariety of subject matters. Like other companies in the technology industry, we face heightened scrutiny from both U.S. \\nand foreign governments with respect to our compliance with laws and regulations. Many of these laws and regulations \\nare evolving and their applicability and scope, as interpreted by the courts, remain uncertain.\\nOur compliance with these laws and regulations may be onerous and could, individually or in the aggregate, \\nincrease our cost of doing business, make our products and services less useful, limit our ability to pursue certain \\nbusiness models, cause us to change our business practices, affect our competitive position relative to our peers, and/\\nor otherwise have an adverse effect on our business, reputation, financial condition, and operating results. \\nFor additional information about government regulation applicable to our business, see Risk Factors in Item 1A, \\nTrends in Our Business and Financial Effect in Part II, Item 7, and Legal Matters in Note 10 of the Notes to \\nConsolidated Financial Statements included in Part II, Item 8 of this Annual Report on Form 10-K.\\nIntellectual  Property\\nWe rely on various intellectual property laws, confidentiality procedures and contractual provisions to protect our \\nproprietary technology and our brand. We have registered, and applied for the registration of, U.S. and international \\ntrademarks, service marks, domain names and copyrights. We have also filed patent applications in the U.S. and \\nforeign countries covering certain of our technology, and acquired patent assets to supplement our portfolio. We have \\nlicensed in the past, and expect that we may license in the future, certain of our rights to other parties. For additional \\ninformation, see Risk Factors in Item 1A of this Annual Report on Form 10-K.\\nAvailable Information\\nOur website is located at www.abc.xyz, and our investor relations website is located at www.abc.xyz/investor. Our \\nAnnual Reports on Form 10-K, Quarterly Reports on Form 10-Q, Current Reports on Form 8-K, and our Proxy \\nStatements, and any amendments to these reports, are available through our investor relations website, free of charge, \\nafter we file them with the SEC. We also provide a link to the section of the SEC's website at www.sec.gov that has all \\nof the reports that we file or furnish with the SEC.\\nWe webcast via our investor relations website our earnings calls and certain events we participate in or host with \\nmembers of the investment community. Our investor relations website also provides notifications of news or \\nannouncements regarding our financial performance and other items that may be material or of interest to our \\ninvestors, including SEC filings, investor events, press and earnings releases, and blogs. We also share Google news \\nand product updates on Google's Keyword blog at https://www.blog.google/, that may be material or of interest to our \\ninvestors. Further, corporate governance information, including our certificate of incorporation, bylaws, governance Table of Contents Alphabet Inc.\\n9\",\n          \"General andAdministrative\\nThefollowing table presents ourgeneral andadministrative expenses (inmillions, unaudited):\\nThree Months Ended\\n March 31,\\n 2019 2020\\nGeneral and administrative expenses $ 2,088 $ 2,880\\nGeneral and administrative expenses as a percentage of revenues 5.7% 7.0%\\nGeneral andadministrative expenses consist primarily of:\\n\\u2022Compensation expenses (including SBC) andfacilities-related costs foremployees inourfinance, human\\nresources, information technology ,andlegal organizations;\\n\\u2022Depreciation;\\n\\u2022Equipment-related expenses;\\n\\u2022Legal-related expenses; and\\n\\u2022Professional services fees primarily related toaudit, information technology consulting, outside legal, and\\noutsourcing services.\\nGeneral andadministrative expenses increased $792 million from thethree months ended March 31,2019 to\\nthethree months ended March 31,2020 .Oftheincrease $413 million wasduetoanincrease inallowance forcredit\\nlosses foraccounts receivable primarily related totheeconomic impact ofCOVID-19. Inaddition, compensation\\nexpenses (including SBC) andfacilities-related costs increased $341 million, largely resulting from an18% increase\\ninheadcount.\\nOver time, general and administrative expenses asapercentage ofrevenues may fluctuate due tocertain\\nexpenses thataregenerally less variable innature andmay notcorrelate tothechanges inrevenues, theeffectof\\ndiscrete items such aslegal settlements, orfurther allowances forcredit losses foraccounts receivable associated\\nwiththeeconomic impact ofCOVID-19.\\nEuropean Commission Fines\\nInMarch 2019, theECannounced itsdecision thatcertain contractual provisions inagreements thatGoogle\\nhadwithAdSense forSearch partners infringed European competition law.TheECdecision imposed a\\u20ac1.5 billion\\n($1.7 billion asofMarch 20,2019) fine, which wasaccrued inthefirstquarter of2019.\\nPlease refer toNote 10oftheNotes toConsolidated Financial Statements included inPart 1,Item 1ofthis\\nQuarterly Report onForm 10-Q forfurther information.\\nOther Income (Expense), Net\\nThefollowing table presents other income (expense), net(inmillions, unaudited):\\nThree Months Ended\\n March 31,\\n 2019 2020\\nOther income (expense), net $ 1,538 $ (220)\\nOther income (expense), net,decreased $1,758 million from thethree months ended March 31,2019 tothe\\nthree months ended March 31,2020 .The decrease was primarily driven by$814 million ofnetlosses, including\\nimpairments, onequity securities forthethree months ended March 31,2020 compared toa$1,083 million netgain\\nonequity securities forthethree months ended March 31,2019 .\\nOver time, other income (expense), net,may beaffected bymarket dynamics andother factors. Equity values\\ngenerally change daily formarketable equity securities andupon theoccurrence ofobservable price changes or\\nupon impairment ofnon-marketable equity securities. Inaddition, volatility intheglobal economic climate and\\nfinancial markets, including theeffects ofCOVID-19, could result inasignificant change inthevalue ofour\\ninvestments. Fluctuations inthevalue ofthese investments has, and weexpect willcontinue to,contribute to\\nvolatility ofOI&E infuture periods. Foradditional information about ourinvestments, seeNote 3oftheNotes to\\nConsolidated Financial Statements included inPart I,Item 1ofthisQuarterly Report onForm 10-Q.Table of Contents Alphabet Inc.\\n40\",\n          \"12With a security infrastructure built into our products, \\nwe work to keep people safe at scale and help them feel confident as they navigate their digital world. In 2022, we shared a new account safety status feature across our apps to flag action that needs to be taken to further secure Google Accounts; continued our work toward a passwordless future with passkey,  \\na new credential to unlock your account; and made updates to resources like virtual cards and SafeSearch to protect payment information and help filter explicit content for families.Google has always provided a secure cloud infrastructure, with more than 6 million websites protected from fraud and bots by our cybersecurity technology. We strengthened our leadership in this area with the acquisition of Mandiant, adding industry-leading threat intelligence and incident response capabilities. In 2022, Mandiant helped  \\nmore than 1,800 customers prepare for or recover from critical cybersecurity incidents.Building trust by  \\n building a safer digital world\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.218685905353968,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          9.0,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page27_mepier.jpeg\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page17_vvhblj.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          [\n            643,\n            468\n          ],\n          [\n            465,\n            520\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_metadata_flash[pdf_metadata_flash['image_available']==True].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKcYaK1WxWDE",
        "outputId": "ad575369-81d2-4666-a878-31c051f35206"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_metadata_flash[pdf_metadata_flash['image_available']==True].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "EI4YpcfHyzai",
        "outputId": "3b127dc5-cf31-404d-e58b-e34cc0c7e4b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text_type                                          file_name  \\\n",
              "17  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "18  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "\n",
              "                                             gcs_path  page_number  \\\n",
              "17  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "18  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "\n",
              "                                                 text  image_available  \\\n",
              "17  Productivity Goodput, to measure this e\u0000ciency...             True   \n",
              "18  how you can measure and maximize runtime for\\n...             True   \n",
              "\n",
              "    image_counter                                     image_gcs_path  \\\n",
              "17            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "18            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "     image_size  \n",
              "17  (2200, 924)  \n",
              "18  (2200, 941)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc13baff-dae4-4a7b-bf99-3a975fd1bd39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Productivity Goodput, to measure this e\u0000ciency...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 924)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>how you can measure and maximize runtime for\\n...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 941)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc13baff-dae4-4a7b-bf99-3a975fd1bd39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc13baff-dae4-4a7b-bf99-3a975fd1bd39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc13baff-dae4-4a7b-bf99-3a975fd1bd39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22332707-757e-4593-b981-7fcf9364a386\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22332707-757e-4593-b981-7fcf9364a386')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22332707-757e-4593-b981-7fcf9364a386 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pdf_metadata_flash[pdf_metadata_flash['image_available']==True]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"how you can measure and maximize runtime for\\nyour large-scale training jobs on Google Cloud.\\nProgram Goodput measures the fraction of peak\\nhardware pe\\u0000ormance that the training job can\\nextract. Program Goodput is also referred to as\\nModel Flop Utilization or e\\u0000ective model \\u0000op\\nutilization, i.e., the model training throughput as a\\nfraction of peak throughput of the system.\\nProgram Goodput depends on factors such as\\ne\\u0000cient compute communication overlaps and\\ncareful distribution strategies to scale e\\u0000ciently\\nto the desired number of accelerators.\\nGoogle\\u2019s AI\\nHypercomputer\\nAI Hypercomputer is a supercomputing\\narchitecture that incorporates a carefully selected\\nset of functions built through systems-level\\ncodesign to boost ML productivity across AI\\ntraining, tuning, and serving applications. The\\nfollowing diagram illustrates how di\\u0000erent\\nelements of ML Productivity Goodput are\\nencoded into AI Hypercomputer:\\nContact sales Get started for free Cloud Blog8/13/24, 8:06 PM Goodput metric as measure of ML productivity | Google Cloud Blog\\nhttps://cloud.google.com/blog/products/ai-machine-learning/goodput-metric-as-measure-of-ml-productivity 4/14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/goodput_metric_as_measure_of_ml_productivity___google_cloud_blog_page4_psxldf.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          [\n            2200,\n            941\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Features from Image Files"
      ],
      "metadata": {
        "id": "LVetWzcHZgCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash = pdf_metadata_flash[pdf_metadata_flash['image_available']==True]"
      ],
      "metadata": {
        "id": "lo5i85RAx7Se"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHBbjO77x_km",
        "outputId": "da6dec5b-c37d-4ed2-fc18-96650af36043"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "6sYDzPm6yBMq",
        "outputId": "d15f3751-c130-4715-f89e-311b8c0321dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text_type                                          file_name  \\\n",
              "17  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "18  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "\n",
              "                                             gcs_path  page_number  \\\n",
              "17  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "18  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "\n",
              "                                                 text  image_available  \\\n",
              "17  Productivity Goodput, to measure this e\u0000ciency...             True   \n",
              "18  how you can measure and maximize runtime for\\n...             True   \n",
              "\n",
              "    image_counter                                     image_gcs_path  \\\n",
              "17            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "18            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "     image_size  \n",
              "17  (2200, 924)  \n",
              "18  (2200, 941)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9491a61d-aa63-4c1f-97a1-f7e71863444e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Productivity Goodput, to measure this e\u0000ciency...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 924)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>how you can measure and maximize runtime for\\n...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 941)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9491a61d-aa63-4c1f-97a1-f7e71863444e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9491a61d-aa63-4c1f-97a1-f7e71863444e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9491a61d-aa63-4c1f-97a1-f7e71863444e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a54e9572-797a-43c6-ae3c-d0e6ac62e333\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a54e9572-797a-43c6-ae3c-d0e6ac62e333')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a54e9572-797a-43c6-ae3c-d0e6ac62e333 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "image_metadata_flash",
              "summary": "{\n  \"name\": \"image_metadata_flash\",\n  \"rows\": 128,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"annual_report\",\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 2,\n        \"max\": 33,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          31,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"30\\u201cWe just don\\u2019t have \\nthe same climate we \\nused to. Technology \\nallows us to continue \\nto push forward so the \\nvineyards will outlast us.\\u201d\\n\\u2013 Riggs Lokka, Emeritus Vineyards\\nAdam Koeppel and Tyler Locke co-founded Agrology \\nto help farmers adapt to changing climates. Using \\nGoogle Cloud with TensorFlow, public benefit \\ncorporation Agrology runs machine learning models \\non sensor data to provide predictive insights for growers like multigeneration Emeritus Vineyards.\",\n          \"25\\nYear in Review 2022We also continued to bring improvements to our \\nproducts to help them work better for everyone. For people with disabilities, speech recognition is an increasingly important dimension of how people interact with technology, and in 2022, we joined the Speech Accessibility Project, a collaboration between researchers at the University of Illinois Urbana-Champaign and five technology companies. The university is working with advocacy groups, like Team Gleason and the Davis Phinney Foundation, to create data sets of impaired speech that can help accelerate improvements to automated speech recognition (ASR), a key step toward supporting more than  \\n1.5 billion people who are hearing impaired worldwide.\\nEach year we seek ways to make sure our products represent our world. In 2021, we launched Real Tone for Pixel \\u2013 technology to capture and create more accurate images of people of color \\u2013 and in 2022,  \\nwe built on that work by adopting the Monk Skin  \\nTone Scale. This tool, created by Harvard professor  \\nDr. Ellis Monk, offers a broader spectrum of skin tones to inform the technology development process. Beyond Pixel, we started using it to achieve more equitable representation in Search, Google Photos, and more.\\nMonk Scale\\nThe Monk Skin Tone Scale offers a broader range of skin tone shades than is typically used in technology development, helping us build products that better reflect the spectrum of skin tones we see in the world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.218685905353968,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page27_mepier.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          [\n            643,\n            468\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=120),stop=stop_after_attempt(2))\n",
        "async def async_generate_df(session, page_text, prompt, gcs_uri):\n",
        "    try:\n",
        "        safety_settings = {\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        }\n",
        "        model = GenerativeModel(\n",
        "            \"gemini-1.5-flash-001\",\n",
        "            safety_settings = safety_settings\n",
        "        )\n",
        "        final_prompt = prompt + \"**page_text:** \\n\" + page_text\n",
        "        response = await model.generate_content_async(\n",
        "            [final_prompt, Part.from_uri(gcs_uri, mime_type='image/png')],\n",
        "            stream=False,\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(\"Something failed, retrying\")\n",
        "        print(e)\n",
        "        with retry.stop_after_attempt(2) as retry_state:\n",
        "            if retry_state.attempt > 2:\n",
        "                return None\n",
        "        raise  # Re-raise the exception for tenacity to handle\n",
        "\n",
        "\n",
        "async def process_row(row, session, semaphore):\n",
        "    async with semaphore:\n",
        "        return await async_generate_df(session, row['text'], image_description_prompt, row['image_gcs_path'])\n",
        "\n",
        "async def process_dataframe(df, batch_size=100, max_concurrency=10):\n",
        "    semaphore = asyncio.Semaphore(max_concurrency)\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        # Measure initial memory usage\n",
        "        initial_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
        "\n",
        "        # Start a timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(f\"Batch size: {batch_size}\")\n",
        "        print(f\"Initial memory usage: {initial_memory_usage:.2f} MB\")\n",
        "\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            chunk = df[i:i+batch_size]\n",
        "            tasks = [process_row(row, session, semaphore) for index, row in chunk.iterrows()]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "            for index, result in enumerate(results):\n",
        "                df.loc[chunk.index[index], 'image_description'] = result\n",
        "\n",
        "        # Measure final memory usage\n",
        "        final_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
        "\n",
        "        # Calculate elapsed time\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "        print(f\"Final memory usage: {final_memory_usage:.2f} MB\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "wmDnm9YYJsJq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_description_prompt = \"\"\"You are a technical image analysis expert. You will be provided with various types of images extracted from documents like research papers, technical blogs, and more.\n",
        "Your task is to generate concise, accurate descriptions of the images without adding any information you are not confident about.\n",
        "Focus on capturing the key details, trends, or relationships depicted in the image. Use provided **page_text:** to ground the generation.\n",
        "\n",
        "Important Guidelines:\n",
        "* Prioritize accuracy:  If you are uncertain about any detail, state \"Unknown\" or \"Not visible\" instead of guessing.\n",
        "* Avoid hallucinations: Do not add information that is not directly supported by the image.\n",
        "* Be specific: Use precise language to describe shapes, colors, textures, and any interactions depicted.\n",
        "* Consider context in Image: If the image is a screenshot or contains text, incorporate that information into your description.\n",
        "* Consider context of Page: Consider the **page_text:** to understand the context of the image.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XesgSXXSaJtH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash_final = await process_dataframe(image_metadata_flash, batch_size=10, max_concurrency=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6-Eo37tKUoI",
        "outputId": "21f86177-c909-4a6c-d2b0-9b75a0745cd2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 10\n",
            "Initial memory usage: 632.40 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cf33daf03f63>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[chunk.index[index], 'image_description'] = result\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 68.04 seconds\n",
            "Final memory usage: 643.77 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash_final.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "70pu86hbbZVw",
        "outputId": "0d9a28d0-49d2-49c7-edbf-2473aa5c12f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text_type                                          file_name  \\\n",
              "17  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "18  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "\n",
              "                                             gcs_path  page_number  \\\n",
              "17  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "18  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "\n",
              "                                                 text  image_available  \\\n",
              "17  Productivity Goodput, to measure this e\u0000ciency...             True   \n",
              "18  how you can measure and maximize runtime for\\n...             True   \n",
              "\n",
              "    image_counter                                     image_gcs_path  \\\n",
              "17            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "18            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "     image_size                                  image_description  \n",
              "17  (2200, 924)  The image depicts a diagram illustrating the t...  \n",
              "18  (2200, 941)  The diagram depicts the elements of ML Product...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b08a502-2dec-42aa-a272-3689bc5eae97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "      <th>image_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Productivity Goodput, to measure this e\u0000ciency...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 924)</td>\n",
              "      <td>The image depicts a diagram illustrating the t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>how you can measure and maximize runtime for\\n...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 941)</td>\n",
              "      <td>The diagram depicts the elements of ML Product...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b08a502-2dec-42aa-a272-3689bc5eae97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b08a502-2dec-42aa-a272-3689bc5eae97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b08a502-2dec-42aa-a272-3689bc5eae97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4d1fe3c-df06-41f5-a015-4576e239308b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4d1fe3c-df06-41f5-a015-4576e239308b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4d1fe3c-df06-41f5-a015-4576e239308b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "image_metadata_flash_final",
              "summary": "{\n  \"name\": \"image_metadata_flash_final\",\n  \"rows\": 128,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"annual_report\",\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 2,\n        \"max\": 33,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          31,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"30\\u201cWe just don\\u2019t have \\nthe same climate we \\nused to. Technology \\nallows us to continue \\nto push forward so the \\nvineyards will outlast us.\\u201d\\n\\u2013 Riggs Lokka, Emeritus Vineyards\\nAdam Koeppel and Tyler Locke co-founded Agrology \\nto help farmers adapt to changing climates. Using \\nGoogle Cloud with TensorFlow, public benefit \\ncorporation Agrology runs machine learning models \\non sensor data to provide predictive insights for growers like multigeneration Emeritus Vineyards.\",\n          \"25\\nYear in Review 2022We also continued to bring improvements to our \\nproducts to help them work better for everyone. For people with disabilities, speech recognition is an increasingly important dimension of how people interact with technology, and in 2022, we joined the Speech Accessibility Project, a collaboration between researchers at the University of Illinois Urbana-Champaign and five technology companies. The university is working with advocacy groups, like Team Gleason and the Davis Phinney Foundation, to create data sets of impaired speech that can help accelerate improvements to automated speech recognition (ASR), a key step toward supporting more than  \\n1.5 billion people who are hearing impaired worldwide.\\nEach year we seek ways to make sure our products represent our world. In 2021, we launched Real Tone for Pixel \\u2013 technology to capture and create more accurate images of people of color \\u2013 and in 2022,  \\nwe built on that work by adopting the Monk Skin  \\nTone Scale. This tool, created by Harvard professor  \\nDr. Ellis Monk, offers a broader spectrum of skin tones to inform the technology development process. Beyond Pixel, we started using it to achieve more equitable representation in Search, Google Photos, and more.\\nMonk Scale\\nThe Monk Skin Tone Scale offers a broader range of skin tone shades than is typically used in technology development, helping us build products that better reflect the spectrum of skin tones we see in the world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.218685905353968,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page27_mepier.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          [\n            643,\n            468\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"The image shows a close-up of a Black woman's face. She is smiling and looking directly at the camera. She has long black hair in dreadlocks and is wearing a blue t-shirt with the word \\\"adidas\\\" visible. The background is a light-colored wall.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_flash_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOScvXFmfdeh",
        "outputId": "f3076057-3bbc-4f6f-b357-d63b5b05b4fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 7\n",
        "print(\"********Page Text: ********\")\n",
        "rich_Markdown(image_metadata_flash_final.iloc[index]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "_dTHig1CeyGp",
        "outputId": "2fc605f8-fb24-4b0a-9d75-682241513606"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********Page Text: ********\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model as a Service Endpoint The Model as a Service Endpoint is an architectural best practice that is comprised of \n",
              "three major Cloud components: ���App Hub recently launched to general availability. App Hub is a central place for \n",
              "tracking applications, services, and workloads across your Cloud projects. It maintains records of your services to\n",
              "enable their discoverability & reusability, including your AI applications and models.  ���Private Service Connect \n",
              "(PSC) for secure connectivity to AI models. This allows model producers to de�ne a PSC service a�achment that model\n",
              "consumers can connect to in order to access gen AI models for inference. The model producer de�nes policies on who \n",
              "can access the gen AI models. PSC also simpli�es cross network access between consumer applications and producer   \n",
              "models, includingContact sales Get started for free Cloud Blog8/13/24, 8:07 PM Networking capabilities optimize    \n",
              "trafﬁc for generative AI apps | Google Cloud Blog                                                                  \n",
              "https://cloud.google.com/blog/products/networking/networking-capabilities-optimize-trafﬁc-for-generative-ai-apps   \n",
              "6/13                                                                                                               \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model as a Service Endpoint The Model as a Service Endpoint is an architectural best practice that is comprised of \n",
              "three major Cloud components: ���App Hub recently launched to general availability. App Hub is a central place for \n",
              "tracking applications, services, and workloads across your Cloud projects. It maintains records of your services to\n",
              "enable their discoverability &amp; reusability, including your AI applications and models.  ���Private Service Connect \n",
              "(PSC) for secure connectivity to AI models. This allows model producers to de�ne a PSC service a�achment that model\n",
              "consumers can connect to in order to access gen AI models for inference. The model producer de�nes policies on who \n",
              "can access the gen AI models. PSC also simpli�es cross network access between consumer applications and producer   \n",
              "models, includingContact sales Get started for free Cloud Blog8/13/24, 8:07 PM Networking capabilities optimize    \n",
              "trafﬁc for generative AI apps | Google Cloud Blog                                                                  \n",
              "https://cloud.google.com/blog/products/networking/networking-capabilities-optimize-trafﬁc-for-generative-ai-apps   \n",
              "6/13                                                                                                               \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"********Image Description: ********\")\n",
        "rich_Markdown(image_metadata_flash_final.iloc[index]['image_description'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "1llYeORmKs2W",
        "outputId": "49bc0e57-b8c5-4723-fec0-2ccdb0c9d6dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********Image Description: ********\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "The image depicts a Model as a Service Endpoint architecture with three layers: Application Serving Tier, Google   \n",
              "Cloud Workloads and Model Inference. Clients access the Application Serving Tier, which uses Cloud Load Balancing  \n",
              "to distribute requests. These requests are directed to the Model Service Endpoint within Google Cloud Workloads.   \n",
              "The Model Service Endpoint consists of App Hub (which tracks applications, services, and workloads across Cloud    \n",
              "projects) and Private Service Connect (PSC) for secure connectivity to AI models. Model Producers can define access\n",
              "policies for their models through PSC. The Model Inference layer handles the actual model execution, utilizing both\n",
              "pre-trained models from Vertex AI and DIY models, all running on TPUs and GPUs.  The image also shows how models   \n",
              "can be accessed from different environments: multi-cloud, on-premise, and by model consumers.                      \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The image depicts a Model as a Service Endpoint architecture with three layers: Application Serving Tier, Google   \n",
              "Cloud Workloads and Model Inference. Clients access the Application Serving Tier, which uses Cloud Load Balancing  \n",
              "to distribute requests. These requests are directed to the Model Service Endpoint within Google Cloud Workloads.   \n",
              "The Model Service Endpoint consists of App Hub (which tracks applications, services, and workloads across Cloud    \n",
              "projects) and Private Service Connect (PSC) for secure connectivity to AI models. Model Producers can define access\n",
              "policies for their models through PSC. The Model Inference layer handles the actual model execution, utilizing both\n",
              "pre-trained models from Vertex AI and DIY models, all running on TPUs and GPUs.  The image also shows how models   \n",
              "can be accessed from different environments: multi-cloud, on-premise, and by model consumers.                      \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Features from Audio Files"
      ],
      "metadata": {
        "id": "uPrMfuAUSSTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=120),stop=stop_after_attempt(2))\n",
        "async def async_generate(prompt, gcs_uri, mime_type):\n",
        "    try:\n",
        "        safety_settings = {\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "        }\n",
        "        model = GenerativeModel(\n",
        "            \"gemini-1.5-flash-001\",\n",
        "            safety_settings = safety_settings\n",
        "        )\n",
        "        # print(\"Hitting\")\n",
        "\n",
        "        response = await model.generate_content_async(\n",
        "            [prompt, Part.from_uri(gcs_uri, mime_type=mime_type)],\n",
        "            stream=False,\n",
        "        )\n",
        "        # print(len(response.text))\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(\"Something failed, retrying\")\n",
        "        print(e)\n",
        "        with retry.stop_after_attempt(2) as retry_state:\n",
        "            if retry_state.attempt > 2:\n",
        "                return None\n",
        "        raise  # Re-raise the exception for tenacity to handle\n",
        "\n",
        "async def batch_and_profile(gcs_uris, prompt, mime_type, batch_size=2, max_concurrent=4):\n",
        "    start_time = time.time()\n",
        "    memory_usage = psutil.Process().memory_info().rss / 1024**2\n",
        "\n",
        "    semaphore = asyncio.locks.Semaphore(max_concurrent)\n",
        "    async def process_batch(batch):\n",
        "        async with semaphore:\n",
        "            return await asyncio.gather(*[async_generate(prompt, f, mime_type) for f in batch])\n",
        "\n",
        "    batches = [gcs_uris[i:i+batch_size] for i in range(0, len(gcs_uris), batch_size)]\n",
        "    get_responses = [asyncio.create_task(process_batch(batch)) for batch in batches]\n",
        "    final_response_list = [item for sublist in await asyncio.gather(*get_responses) for item in sublist]\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    final_memory_usage = psutil.Process().memory_info().rss / 1024**2\n",
        "\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Initial memory usage: {memory_usage:.2f} MB\")\n",
        "    print(f\"Final memory usage: {final_memory_usage:.2f} MB\")\n",
        "\n",
        "    return final_response_list\n",
        "\n",
        "def get_gcs_uri_list(bucket,data,file_extension):\n",
        "  gcs_uri_list = []\n",
        "  for blob in bucket.list_blobs():\n",
        "      if blob.name.startswith(data):\n",
        "        if blob.name.lower().endswith(file_extension):\n",
        "          gcs_path = \"gs://\"+\"/\".join(blob.id.split(\"/\")[:-1])\n",
        "          gcs_uri_list.append(gcs_path)\n",
        "  return gcs_uri_list"
      ],
      "metadata": {
        "id": "SF8_wfCqKBOe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_uri_list_audio = get_gcs_uri_list(bucket,production_data,'.mp3')"
      ],
      "metadata": {
        "id": "3E00-jQaKzht"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_uri_list_audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iEhXSxHK0Wf",
        "outputId": "c69715d0-1625-4807-984c-3181ea5d73c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2023 Q2 Earnings Call (128 kbps).mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2023 Q3 Earnings Call (128 kbps).mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2024 Q2 Earnings Call (128 kbps).mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q1_Earnings_Call.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q4_Earnings_Call.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2024_Q1_Earnings_Call.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode1.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode2.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode3.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode4.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode5.mp3',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode6.mp3']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gcs_uri_list_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MQHnz5HLeio",
        "outputId": "e28c3ca6-eefe-40dc-d425-c7d0d5b70d65"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "max_concurrent = 4\n",
        "audio_description_extraction_prompt = \"\"\"Transcribe and analyze the audio, identifying key topic shifts or changes in focus. Divide the audio into segments based on these transitions.\n",
        "For each segment:\n",
        "* **Summarize:** Briefly describe the main topic or theme of the segment.\n",
        "* **Contextualize:** Explain how this topic fits into the broader conversation or narrative.\n",
        "* **Analyze:** Explore the significance of this topic, the perspectives presented, and any potential biases or underlying assumptions.\n",
        "* **Synthesize:** Connect this topic to other themes or ideas medntioned in the audio, highlighting relationships and overarching patterns.\n",
        "Conclude with a thematic analysis of the entire audio. Identify the most prominent themes, how they are interconnected, and the overall message or purpose of the audio.\n",
        "\"\"\"\n",
        "\n",
        "final_response_list_audio = await batch_and_profile(gcs_uri_list_audio,\n",
        "                                                    audio_description_extraction_prompt,\n",
        "                                                    \"audio/mpeg\",\n",
        "                                                    batch_size, max_concurrent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpl-WEFYPHtA",
        "outputId": "c4451662-5685-4b1a-dd82-8ca6aae10cf3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 3\n",
            "Elapsed time: 61.78 seconds\n",
            "Initial memory usage: 643.75 MB\n",
            "Final memory usage: 643.84 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata_flash = pd.DataFrame([gcs_uri_list_audio, final_response_list_audio]).T\n",
        "audio_metadata_flash.columns = ['audio_gcs', 'audio_description']\n",
        "audio_metadata_flash.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wb0MHXxxShIc",
        "outputId": "0f8e2134-0822-4419-92ff-0768d4391690"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           audio_gcs  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "                                   audio_description  \n",
              "0  ## Alphabet's Second Quarter 2023 Earnings Con...  \n",
              "1  ## Alphabet Third Quarter 2023 Earnings Confer...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-266a1675-68d7-4f32-9e54-428e58eb9c8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_gcs</th>\n",
              "      <th>audio_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Alphabet's Second Quarter 2023 Earnings Con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Alphabet Third Quarter 2023 Earnings Confer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-266a1675-68d7-4f32-9e54-428e58eb9c8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-266a1675-68d7-4f32-9e54-428e58eb9c8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-266a1675-68d7-4f32-9e54-428e58eb9c8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eab5e4f8-7fe4-4722-85da-f3d41760cc93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eab5e4f8-7fe4-4722-85da-f3d41760cc93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eab5e4f8-7fe4-4722-85da-f3d41760cc93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "audio_metadata_flash",
              "summary": "{\n  \"name\": \"audio_metadata_flash\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"audio_gcs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode5.mp3\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode4.mp3\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2023 Q2 Earnings Call (128 kbps).mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"## Transcript and Analysis of Audio:\\n\\n**Segment 1:  AI and the Green Transition (0:00 - 2:07)**\\n\\n* **Summary:** The conversation begins with a discussion about the potential of AI to accelerate the transition to a green and sustainable economy.  Lord Stern highlights the need for pace and system change, arguing that AI's rapid development provides a crucial opportunity to address the climate crisis.\\n* **Contextualization:** This segment sets the stage for the broader conversation by establishing the primary focus on AI's role in addressing climate change and sustainability.\\n* **Analysis:**  Lord Stern presents a positive view of AI's potential, emphasizing its ability to drive change at an unprecedented pace. This perspective suggests an optimistic outlook on AI's capacity to solve complex global challenges.  However, it also implies a potential bias towards technological solutions and might downplay the need for significant societal and policy shifts.\\n* **Synthesis:** This segment connects to the overarching theme of the audio, which explores how AI can contribute to sustainability and global inclusion. The emphasis on pace and system change establishes a framework for the subsequent discussion of AI's potential and the challenges it presents.\\n\\n**Segment 2:  The Pace of Progress (2:07 - 5:07)**\\n\\n* **Summary:** The discussion shifts to a closer examination of the pace of progress in addressing climate change.  Lord Stern acknowledges that progress has been slow, particularly in the years leading up to the Paris Agreement in 2015, but highlights a shift towards a cleaner, more sustainable economic model. \\n* **Contextualization:** This segment provides a historical context for the conversation, showing how the urgency of the climate crisis has become more apparent over time. \\n* **Analysis:** The segment highlights the complexity of the problem and the need for a more comprehensive approach that goes beyond technological innovation.  It also suggests that the pace of progress might be inadequate, potentially underestimating the challenges and risks associated with climate change. \\n* **Synthesis:** This segment expands on the previous discussion by introducing the importance of investment and systemic change as crucial elements in accelerating progress. The focus on investment paves the way for the following discussion on how AI can facilitate these changes.\\n\\n**Segment 3: AI and System Change (5:07 - 9:36)**\\n\\n* **Summary:**  Lord Stern emphasizes the potential of AI to drive system change by providing the ability to model and experiment with complex systems without disrupting the real world. He highlights the importance of applying AI to large-scale systems like energy, transportation, and cities to create more efficient and sustainable solutions. \\n* **Contextualization:** This segment explores how AI can be used to create more intelligent and efficient systems, especially in areas that are highly interconnected and require complex solutions.\\n* **Analysis:**  Lord Stern provides concrete examples of how AI can be used to optimize and improve existing systems, illustrating its practical application to real-world challenges.  The focus on systemic change emphasizes the need for a holistic approach to address climate change and sustainability.\\n* **Synthesis:** This segment continues to weave together the themes of AI, sustainability, and systemic change. It explores the potential for AI to optimize large-scale systems, paving the way for the subsequent discussion about the potential social and economic implications of AI.\\n\\n**Segment 4: AI, Adaptation, and the Social Sciences (9:36 - 15:21)**\\n\\n* **Summary:** The conversation shifts to the crucial role of adaptation in addressing climate change and the challenges of using AI to predict and manage complex events, like floods and wildfires. The segment highlights the need for a stronger integration of social sciences with AI to address the social and economic impacts of technological change.\\n* **Contextualization:** This segment shifts the focus from the technical capabilities of AI to its broader societal implications.\\n* **Analysis:**  The segment underscores the importance of adapting to the changing climate and the role of AI in helping communities prepare for and mitigate the impacts of extreme events.  The discussion also highlights the limitations of AI in predicting and managing complex social and economic systems, underscoring the need for a more collaborative approach that integrates social sciences and data-driven insights.\\n* **Synthesis:** This segment expands on the themes of system change and societal implications of AI. It emphasizes the need to consider the social and economic context in which AI is deployed and to invest in people and places to ensure equitable and inclusive outcomes.\\n\\n**Segment 5:  The Challenge of AI and System Change (15:21 - 19:04)**\\n\\n* **Summary:** Lord Stern and the interviewer discuss the challenges of anticipating and managing the social and economic impacts of AI, acknowledging the limited historical data available to guide decision-making.  The segment emphasizes the need to learn from past technological revolutions and to develop a more proactive approach to managing the disruptions caused by new technologies.\\n* **Contextualization:** This segment explores the need for a proactive and ethical approach to AI development and deployment to mitigate potential negative impacts.\\n* **Analysis:** The segment highlights the need for a more robust social scientific understanding of AI and its implications for society. It suggests that AI's rapid development might be outpacing our capacity to fully understand and manage its social and economic consequences. \\n* **Synthesis:** This segment reinforces the importance of collaboration, foresight, and ethical considerations in harnessing the potential of AI for the greater good. The discussion about managing disruptions and investing in people and places lays the groundwork for the final segment.\\n\\n**Segment 6:  AI and the Future (19:04 - 21:36)**\\n\\n* **Summary:** The conversation concludes with a discussion about the potential for AI to accelerate sustainable development and the need for a collective effort to ensure that its benefits are shared equitably. Lord Stern expresses optimism about the future, highlighting the growing global awareness of the need for a clean and sustainable economic model.\\n* **Contextualization:** This segment offers a concluding perspective on the potential of AI to address global challenges and the importance of collaboration and ethical considerations.\\n* **Analysis:**  Lord Stern's closing remarks reiterate the need for a proactive and collaborative approach to AI, emphasizing the importance of education, health, and social equity in harnessing its potential. This perspective suggests a balanced view of AI's potential, recognizing both its benefits and challenges.\\n* **Synthesis:** This segment provides a final reflection on the themes discussed throughout the audio.  It reinforces the overarching message that AI holds significant potential for solving global challenges, but only if developed and deployed ethically and collaboratively, with a focus on social equity and human well-being.\\n\\n**Thematic Analysis:**\\n\\nThe audio explores the intersection of AI, sustainability, and societal change, highlighting several key themes:\\n\\n* **The Urgent Need for Pace and Systemic Change:** The audio emphasizes the urgency of addressing climate change and the need for significant shifts in economic and social systems to achieve sustainability. \\n* **The Potential of AI to Accelerate Progress:** The speakers explore the potential of AI to drive system change, optimize resource use, and develop new technologies for a sustainable future. \\n* **The Challenges of Managing Social and Economic Impacts:** The audio acknowledges the potential disruptions caused by AI and the need for proactive measures to manage its social and economic impacts.  \\n* **The Importance of Collaboration and Ethical Considerations:** The speakers highlight the importance of a collective effort and ethical considerations in the development and deployment of AI to ensure equitable and inclusive outcomes.\\n\\nThe overarching message of the audio is that AI holds significant potential for solving global challenges, including climate change, but only if developed and deployed in a way that prioritizes social well-being and equity, and that takes into account its complex social and economic implications. The conversation emphasizes the need for a more proactive, collaborative, and ethical approach to AI, one that considers the needs of all stakeholders and ensures that its benefits are shared equitably. \\n\",\n          \"## Transcript and Analysis of Audio:\\n\\n**Segment 1: The Internet's Impact on Democracy (0:37 - 2:04)**\\n\\n* **Summary:**  Rory Stewart argues that the internet, particularly social media, has had a negative impact on democracy by fostering a climate of polarization and undermining the traditional values of compromise and persuasion. He points to the decline in the number of democracies worldwide since 2004 and the rise of extreme and uncompromising viewpoints online as evidence of this trend.\\n* **Contextualize:**  This segment sets the stage for the conversation about AI and its potential impact on democracy. By highlighting the internet's challenges to democratic principles, it frames AI as a potential continuation or exacerbation of these issues.\\n* **Analyze:**  Stewart's perspective is rooted in a concern for the decline of traditional democratic norms. He suggests that social media algorithms, designed for engagement and attention-grabbing, have led to a shift away from reasoned debate and towards the amplification of extreme views.  This perspective reflects a potential bias towards older models of political discourse and a skepticism about the ability of the internet to facilitate productive civic engagement.\\n* **Synthesize:** The segment connects the internet's impact to the broader theme of democratic values, foreshadowing the discussion about how AI might interact with these principles.\\n\\n**Segment 2: The Internet and Open Societies (2:04 - 3:34)**\\n\\n* **Summary:** The conversation shifts to the contrast between internet use in open societies and in more oppressive regimes. Stewart argues that democracies face a greater challenge in navigating the internet's potential to undermine democratic values, as they strive for open dialogue and dissent.\\n* **Contextualize:** This segment expands the discussion beyond the negative impact of social media by acknowledging the internet's potential for empowerment and positive change. It also introduces the idea of \\\"attributes of discourse\\\" as a key factor in shaping the internet's influence.\\n* **Analyze:** The comparison between open societies and restrictive regimes highlights the complexities of the internet's influence.  While authoritarian regimes can control internet access and content, democracies must grapple with the challenges of navigating free speech and preventing the spread of misinformation. This segment highlights the potential for AI to play a role in managing online discourse, shaping it towards more constructive and democratic outcomes.\\n* **Synthesize:** This segment builds upon the previous discussion about democracy by emphasizing the need for a more deliberate approach to internet governance, particularly in open societies.\\n\\n**Segment 3: The Role of Persuasion in Democracy (3:34 - 4:45)**\\n\\n* **Summary:** Stewart emphasizes the importance of persuasion in democratic dialogue. He argues that democracy requires a willingness to listen to opposing viewpoints, engage in reasoned argumentation, and potentially change one's mind. He contrasts this with the current trend of politicians mobilizing their bases against each other.\\n* **Contextualize:** This segment delves deeper into the erosion of democratic norms, highlighting the lack of open dialogue and the rise of polarization. It sets the stage for the discussion about how AI can potentially contribute to or mitigate this trend.\\n* **Analyze:** Stewart's perspective emphasizes the importance of rational discourse and the dangers of tribalism in politics. He criticizes politicians' focus on mobilizing their bases instead of engaging in persuasive argumentation. This perspective highlights the potential role of AI in fostering more civil and reasoned political discourse.\\n* **Synthesize:** This segment reinforces the theme of democratic values and their fragility in the face of contemporary political trends. It also introduces the concept of \\\"radical respect\\\" as a necessary component of democratic dialogue.\\n\\n**Segment 4: Citizen Assemblies and the Internet (4:45 - 7:40)**\\n\\n* **Summary:** The conversation turns to the potential of citizen assemblies as a mechanism for more effective and democratic policymaking. Stewart explains the structure of citizen assemblies and their ability to encourage deliberation and move beyond simple \\\"for\\\" or \\\"against\\\" positions on complex issues.\\n* **Contextualize:** This segment introduces a specific and practical solution to address the challenges of democracy in the digital age. It explores how AI might be used to facilitate citizen assemblies, overcoming logistical barriers and fostering deeper engagement.\\n* **Analyze:**  Stewart's advocacy for citizen assemblies demonstrates a belief in the power of direct citizen participation in shaping policy. He suggests that such forums could promote more informed and nuanced decision-making, countering the polarization of traditional political processes. The segment highlights the potential of AI to create more inclusive and participatory forms of democracy.\\n* **Synthesize:**  This segment connects the theme of democratic values to the practical application of AI in promoting citizen engagement and informed decision-making.\\n\\n**Segment 5: The AI Revolution and its Impact on Politics (7:40 - 10:40)**\\n\\n* **Summary:**  Stewart discusses the potential impact of AI, particularly large language models, on future elections and the challenges of regulating their use. He expresses concern about the potential for AI to be used for manipulating public opinion and spreading misinformation, as well as the difficulty of resisting such tactics.\\n* **Contextualize:** This segment shifts the focus to the more immediate concerns about the influence of AI on political processes. It explores the challenges of regulating AI and the potential for it to be used for harmful purposes.\\n* **Analyze:** Stewart's perspective reflects a cautious approach to the use of AI in politics. He acknowledges its potential for positive change but highlights the dangers of its misuse for manipulation and deception. This segment underscores the urgent need for ethical frameworks and regulatory mechanisms to govern the development and deployment of AI in the political sphere.\\n* **Synthesize:** This segment reinforces the theme of the potential for AI to exacerbate existing challenges to democracy, specifically by enhancing the tools for manipulation and misinformation campaigns.\\n\\n**Segment 6:  AI's Potential for Positive Change and the Importance of Local Democracy (10:40 - 13:48)**\\n\\n* **Summary:** Stewart  highlights positive examples of how AI is being used to address real-world challenges, such as improving productivity and delivering essential services. He emphasizes the importance of local democracy in determining how AI is implemented and tailored to specific needs.\\n* **Contextualize:** This segment presents a more optimistic view of AI, showcasing its potential to address complex social and economic issues. It connects this potential to the need for localized and citizen-driven approaches to governance.\\n* **Analyze:**  This segment balances Stewart's previous concerns about AI's potential for manipulation by highlighting its positive applications. The emphasis on localization suggests that AI can be used to empower citizens and address specific local needs, potentially contributing to a more equitable and participatory democracy.\\n* **Synthesize:** This segment continues to explore the theme of democratic values, but now connects it to the potential of AI for addressing broader societal issues. It highlights the need for a nuanced approach to AI development and deployment, considering both its risks and opportunities.\\n\\n**Segment 7: Trust and the Role of Technology (13:48 - 16:12)**\\n\\n* **Summary:** Stewart emphasizes the need for trust between citizens and technology, arguing that the successful adoption of AI requires a careful balance between optimism and skepticism. He emphasizes the importance of local communities being involved in the design and implementation of AI solutions, allowing for a more responsive and accountable approach to technological change.\\n* **Contextualize:** This segment returns to the overarching theme of navigating the relationship between technology and democracy.  It underscores the need for a collaborative and transparent approach to AI development, ensuring that it serves the needs of citizens rather than being imposed upon them.\\n* **Analyze:**  Stewart's perspective emphasizes the importance of a human-centered approach to AI, prioritizing trust and local participation over technocratic solutions. He cautions against placing blind faith in technology and argues for a more nuanced and participatory approach to its integration into society.\\n* **Synthesize:**  This segment brings the conversation back to the central theme of the audio:  the need to navigate the complex relationship between AI, democracy, and the human experience. It highlights the potential for AI to be a tool for positive change, but only if it is developed and implemented with transparency, trust, and a focus on citizen empowerment.\\n\\n**Thematic Analysis:**\\n\\nThe most prominent themes in the audio are: \\n\\n* **The Future of Democracy:** The audio explores the challenges facing democracy in the age of technology, particularly the internet and AI. Stewart expresses concern about the erosion of traditional democratic norms, such as compromise and persuasion, and the potential for AI to be used for manipulation and misinformation campaigns.\\n* **The Importance of Citizen Engagement:**  Stewart emphasizes the need for citizen participation in shaping policy and navigating technological change. He advocates for localized approaches to governance and the use of citizen assemblies as a mechanism for fostering informed and deliberative decision-making. \\n* **The Power of Trust:** The audio emphasizes the importance of building trust between citizens and technology. Stewart argues that AI must be developed and implemented in a way that is transparent, accountable, and responsive to the needs of local communities. \\n* **The Need for a Human-Centered Approach:** Throughout the conversation, Stewart emphasizes the importance of a human-centered approach to AI development and deployment. He argues against viewing AI as a solution for all problems and highlights the need for careful consideration of its potential consequences for individuals and societies.\\n\\n**Overall Message/Purpose:**\\n\\nThe audio serves as a call for reflection and action regarding the implications of AI for democracy and society. It acknowledges the potential for AI to be a force for good, but warns against the dangers of its misuse for manipulation and control. Ultimately, the audio emphasizes the need for a collaborative and nuanced approach to AI, one that prioritizes citizen empowerment, trust, and a commitment to democratic values. \\n\",\n          \"## Alphabet's Second Quarter 2023 Earnings Conference Call: A Thematic Analysis\\n\\nThis audio transcript of Alphabet's second-quarter earnings conference call reveals a company focused on innovation, particularly in artificial intelligence (AI), while navigating a challenging economic environment. The conversation transitions through several key topic shifts, each offering insights into Alphabet's strategies and priorities:\\n\\n**Segment 1: Introduction and Overview (0:00-1:18)**\\n\\n* **Summary:** This segment introduces the call, identifies the speakers, and provides logistical information for participants.\\n* **Contextualization:** This serves as the initial framework for the call, setting the stage for the discussion of financial performance and key strategic initiatives.\\n* **Analysis:** The introduction highlights the importance of the call, signaling to investors and analysts that Alphabet is actively addressing current challenges and opportunities in the technology landscape.\\n* **Synthesis:**  This segment foreshadows the overarching themes of AI and financial performance, which will be central to the rest of the discussion.\\n\\n**Segment 2:  Sundar Pichai's Opening Remarks (1:19-3:33)**\\n\\n* **Summary:** Sundar Pichai emphasizes the company's progress in AI development, focusing on how AI is being used to improve knowledge, boost creativity and productivity, and drive innovation. He also highlights the importance of responsible AI development.\\n* **Contextualization:** This sets the tone for the call, emphasizing Alphabet's commitment to AI as a core strategic pillar and signaling a shift towards a more AI-driven future.\\n* **Analysis:** Pichai's emphasis on AI reflects the increasing importance of the technology across all of Alphabet's businesses. The discussion of responsible AI development demonstrates the company's awareness of the ethical implications of this rapidly advancing technology.\\n* **Synthesis:** This segment connects to other themes like innovation and efficiency, as AI is portrayed as a catalyst for both.\\n\\n**Segment 3: Sundar Pichai on Search and Google AI (3:34-5:53)**\\n\\n* **Summary:** Pichai discusses the evolution of search, particularly the introduction of the Search Generative Experience (SGE), which leverages generative AI to enhance user experience. He outlines the benefits of this new technology, emphasizing its ability to provide more natural and intuitive search results. \\n* **Contextualization:** This segment delves deeper into one of the key areas where AI is being implemented: Search.\\n* **Analysis:** The introduction of SGE represents a significant shift in how Alphabet is approaching search,  reflecting a belief that generative AI can fundamentally change the way users interact with information.\\n* **Synthesis:** This segment connects to themes of innovation and user experience, demonstrating Alphabet's commitment to continually improving its core products.\\n\\n**Segment 4: Philip Schindler on Ads and AI (5:54-8:56)**\\n\\n* **Summary:** Schindler focuses on how AI is being implemented in Google Ads, showcasing new features and solutions designed to enhance user and advertiser experiences.\\n* **Contextualization:** This segment transitions from the broader focus on AI to a specific application within the advertising space.\\n* **Analysis:** Schindler emphasizes the importance of AI in driving efficiency and effectiveness in the advertising industry, highlighting the company's commitment to leveraging AI to improve ROI for advertisers. \\n* **Synthesis:**  This segment connects to themes of innovation, efficiency, and user experience, illustrating how Alphabet is leveraging AI to enhance its products across various industries.\\n\\n**Segment 5: Ruth Porat on Financial Performance (8:57-14:41)**\\n\\n* **Summary:** Porat provides a detailed overview of Alphabet's second-quarter financial results, highlighting strong revenue growth in Search and continued momentum in Cloud. She also addresses the company's efforts to control expenses and manage profitability.\\n* **Contextualization:** This segment shifts the focus from strategic initiatives to financial performance, providing insights into how the company is performing against its objectives.\\n* **Analysis:** Porat's comments demonstrate a balanced approach to growth and profitability. While acknowledging the challenging economic landscape, she emphasizes Alphabet's commitment to investing in its future while also managing expenses effectively.\\n* **Synthesis:** This segment connects to themes of efficiency, investment, and financial performance, highlighting Alphabet's focus on long-term sustainability.\\n\\n**Segment 6: Q&A: User Behavior, Expenses, AI Strategy (14:42-19:10)**\\n\\n* **Summary:** This segment begins with questions from analysts, focusing on user behavior with Bard, expense control, and Alphabet's AI strategy.\\n* **Contextualization:** This segment allows for a more in-depth exploration of specific topics discussed in the opening remarks.\\n* **Analysis:** The Q&A highlights the key concerns of investors and analysts regarding user adoption of new AI-powered products, the company's commitment to responsible AI development, and the sustainability of its growth trajectory.\\n* **Synthesis:** This segment connects to the themes of user experience, AI development, and financial performance, further emphasizing the central role of AI in Alphabet's strategy.\\n\\n**Segment 7: Q&A: Cloud Growth, Ads and AI (19:11-25:08)**\\n\\n* **Summary:** This segment features questions about Cloud growth, the potential of generative AI in advertising, and the company's overall approach to AI.\\n* **Contextualization:** This builds on the previous segment, providing further insights into Alphabet's performance and strategy within specific business areas. \\n* **Analysis:** The Q&A reveals Alphabet's strong position in the cloud market and highlights the company's plans to leverage generative AI to further enhance its advertising products.\\n* **Synthesis:** This segment reaffirms themes of innovation, growth, and the significance of AI in the company's future.\\n\\n**Segment 8: Q&A: Capex and Real Estate Optimization (25:09-27:44)**\\n\\n* **Summary:**  This segment addresses questions regarding Alphabet's capital expenditures (Capex) and its real estate optimization plans.\\n* **Contextualization:** This returns to the financial performance discussion, focusing on the company's capital allocation strategy and its long-term vision for managing expenses.\\n* **Analysis:**  The responses highlight Alphabet's commitment to responsible spending, balancing growth with efficiency. The company acknowledges the need for investment in AI infrastructure while maintaining a focus on long-term financial sustainability.\\n* **Synthesis:** This segment connects to the themes of investment, efficiency, and financial performance, reinforcing Alphabet's strategy of navigating the current economic climate while investing in its future.\\n\\n**Segment 9: Q&A:  Generative AI and Advertising (27:45- 31:25)**\\n\\n* **Summary:** This segment focuses on the role of generative AI in advertising, highlighting its potential to improve advertiser experiences and drive ROI.\\n* **Contextualization:** This builds on previous discussions about AI in advertising, offering further details on Alphabet's strategy.\\n* **Analysis:** The responses emphasize the significant potential of generative AI to enhance the advertising industry, suggesting a future where AI plays a central role in marketing campaigns.\\n* **Synthesis:** This segment reinforces themes of innovation and efficiency, highlighting how Alphabet is actively using AI to improve its advertising products and services.\\n\\n**Segment 10: Conclusion (31:26-32:36)**\\n\\n* **Summary:** The call concludes with a final thank you to participants and a reminder that the company will hold a similar call for the third quarter.\\n* **Contextualization:** This serves as the closing of the conference call, summarizing the key points discussed and signaling the ongoing nature of the company's strategic initiatives.\\n* **Analysis:**  The closing statement reaffirms Alphabet's commitment to transparency and communication with investors and analysts, signaling a continued focus on its long-term vision.\\n* **Synthesis:**  This segment wraps up the call, leaving a lasting impression of Alphabet's strong focus on AI, growth, and responsible financial management.\\n\\n**Thematic Analysis:**\\n\\nThe most prominent themes throughout the call are:\\n\\n* **AI as a Core Strategic Pillar:** Alphabet consistently emphasizes AI as a central driver of future growth, highlighting its commitment to research, development, and responsible implementation.\\n* **Innovation and Efficiency:**  The company demonstrates a strong focus on innovative solutions that enhance user experiences and drive efficiency for both internal operations and external partners.\\n* **Financial Performance and Sustainability:** While acknowledging the challenging economic environment, Alphabet reaffirms its commitment to profitable growth and sustainable financial performance, demonstrating careful management of expenses and investment in strategic initiatives.\\n\\n**Overall Message:**\\n\\nThis conference call paints a clear picture of Alphabet's long-term vision.  The company is embracing AI as a transformative technology, investing heavily in its research and development, and leveraging its capabilities to improve core products, drive innovation, and enhance user experiences.  At the same time, Alphabet demonstrates a commitment to financial prudence, balancing growth with responsible spending and careful management of resources.  Overall, the call suggests a company well-positioned to capitalize on the future of AI while navigating a dynamic and uncertain economic landscape. \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(audio_metadata_flash.iloc[5]['audio_description'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nckn53ucQaLI",
        "outputId": "e73f8ab8-aab5-4d38-a0f2-a7d9f866c6a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "                    \u001b[1;4mAlphabet's First Quarter 2024 Earnings Conference Call: A Thematic Analysis\u001b[0m                    \n",
              "\n",
              "This audio recording is a transcript of an earnings call for Alphabet, the parent company of Google, for the first \n",
              "quarter of 2024. The call features several key executives, including Sundar Pichai and Philip Schindler, and is    \n",
              "structured around opening statements, a Q&A session, and concluding remarks.                                       \n",
              "\n",
              "Here's a breakdown of the call by segments:                                                                        \n",
              "\n",
              "\u001b[1mSegment 1: Welcome and Introductions (0:00-0:42)\u001b[0m                                                                   \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m The call begins with a welcome by the moderator who introduces the participants and explains the call's\n",
              "\u001b[1;33m   \u001b[0mformat.                                                                                                         \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This is a standard opening for a corporate earnings call, setting the stage for the          \n",
              "\u001b[1;33m   \u001b[0mdiscussion to follow.                                                                                           \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m The introduction emphasizes the importance of investor relations and the procedural aspects of the    \n",
              "\u001b[1;33m   \u001b[0mcall, creating a formal and structured tone.                                                                    \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment provides a clear understanding of the call's purpose and the key figures involved in the\n",
              "\u001b[1;33m   \u001b[0mconversation.                                                                                                   \n",
              "\n",
              "\u001b[1mSegment 2: Sundar Pichai's Overview (0:42-2:59)\u001b[0m                                                                    \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m Sundar Pichai, CEO of Google, highlights the company's strong performance in the first quarter,        \n",
              "\u001b[1;33m   \u001b[0mparticularly in Search, YouTube, and Cloud. He then transitions to a broader discussion of Alphabet's AI        \n",
              "\u001b[1;33m   \u001b[0mstrategy and its position in the AI landscape.                                                                  \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This segment sets the tone for the call by highlighting the importance of AI and its impact  \n",
              "\u001b[1;33m   \u001b[0mon the company's future.                                                                                        \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m Pichai presents a confident and optimistic view of Alphabet's AI capabilities, highlighting its       \n",
              "\u001b[1;33m   \u001b[0mresearch leadership, infrastructure, and global product footprint. He also emphasizes the company's commitment  \n",
              "\u001b[1;33m   \u001b[0mto efficiency and monetization strategies.                                                                      \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment lays the foundation for subsequent discussions on specific product areas, such as       \n",
              "\u001b[1;33m   \u001b[0mSearch, YouTube, and Cloud, by framing them within the overarching context of Alphabet's AI strategy.           \n",
              "\n",
              "\u001b[1mSegment 3: Philip Schindler's Focus on Advertising and YouTube (2:59-7:08)\u001b[0m                                         \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m Philip Schindler, SVP of Ads and Commerce at Google, discusses the company's advertising performance,  \n",
              "\u001b[1;33m   \u001b[0memphasizing the growth of both Search and YouTube ads. He also highlights the success of AI-driven initiatives, \n",
              "\u001b[1;33m   \u001b[0mincluding Smart Bidding and Demand Gen, and the ongoing development of Shorts monetization.                     \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This segment delves into the details of Alphabet's revenue generation strategies, showcasing \n",
              "\u001b[1;33m   \u001b[0mthe company's commitment to growth and innovation within its core advertising business.                         \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m Schindler underscores the importance of AI in optimizing advertising campaigns and reaching targeted  \n",
              "\u001b[1;33m   \u001b[0maudiences. He presents a confident view of the company's future growth prospects, particularly in YouTube, which\n",
              "\u001b[1;33m   \u001b[0mis positioned as a leader in streaming.                                                                         \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment connects with Pichai's earlier emphasis on AI by showcasing the specific ways in which  \n",
              "\u001b[1;33m   \u001b[0mAI is being implemented to enhance advertising performance. It also highlights the interconnectedness of various\n",
              "\u001b[1;33m   \u001b[0mproduct areas, such as YouTube and Search, within Alphabet's broader advertising ecosystem.                     \n",
              "\n",
              "\u001b[1mSegment 4: Ruth Porat's Financial Overview and Outlook (7:08-12:02)\u001b[0m                                                \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m Ruth Porat, CFO of Alphabet, provides a detailed overview of the company's financial performance in the\n",
              "\u001b[1;33m   \u001b[0mfirst quarter, highlighting revenue growth, expense management, and operating margins. She also outlines the    \n",
              "\u001b[1;33m   \u001b[0mcompany's outlook for the rest of the year.                                                                     \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This segment provides the financial context for the previous discussions on AI strategy and  \n",
              "\u001b[1;33m   \u001b[0mproduct performance.                                                                                            \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m Porat emphasizes Alphabet's commitment to profitable growth, showcasing the company's ability to      \n",
              "\u001b[1;33m   \u001b[0mbalance aggressive investments with efficient cost management. She highlights the positive impact of AI on      \n",
              "\u001b[1;33m   \u001b[0mrevenue growth and the ongoing efforts to optimize the company's expense base.                                  \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment further reinforces the importance of AI by highlighting its role in driving revenue     \n",
              "\u001b[1;33m   \u001b[0mgrowth and improving profitability. It also underscores the company's focus on efficiency and long-term         \n",
              "\u001b[1;33m   \u001b[0msustainability.                                                                                                 \n",
              "\n",
              "\u001b[1mSegment 5: Q&A Session (12:02-23:05)\u001b[0m                                                                               \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m This segment consists of a series of questions from analysts, focusing on:                             \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThe impact of AI on Search, particularly monetization strategies and potential changes in search behavior.   \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThe drivers of growth in Cloud and the company's strategy for expanding its market share.                    \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThe company's approach to sports rights, particularly beyond the NFL Sunday Ticket.                          \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mThe significance of the increase in CapEx and its potential implications for future growth.                  \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This segment provides a platform for analysts to probe the details of Alphabet's AI strategy,\n",
              "\u001b[1;33m   \u001b[0mits financial performance, and its future outlook.                                                              \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m The analysts' questions reflect the current market interest in AI and its implications for Alphabet's \n",
              "\u001b[1;33m   \u001b[0mbusiness. The responses from executives offer insights into the company's internal thinking and its strategy for\n",
              "\u001b[1;33m   \u001b[0mnavigating the evolving AI landscape.                                                                           \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment builds upon the themes established in the opening statements, providing further insights\n",
              "\u001b[1;33m   \u001b[0minto Alphabet's strategic priorities. It also highlights the importance of collaboration and partnerships in    \n",
              "\u001b[1;33m   \u001b[0mdriving innovation and achieving long-term goals.                                                               \n",
              "\n",
              "\u001b[1mSegment 6: Closing Remarks (23:05-23:49)\u001b[0m                                                                           \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSummary:\u001b[0m The call concludes with a thank you to the participants and a reminder of the next earnings call date. \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mContextualization:\u001b[0m This is a standard closing for a corporate earnings call, concluding the formal conversation.\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAnalysis:\u001b[0m The closing remarks reiterate the company's commitment to transparency and communication with         \n",
              "\u001b[1;33m   \u001b[0minvestors.                                                                                                      \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mSynthesis:\u001b[0m This segment provides a sense of closure and reinforces the key messages presented throughout the    \n",
              "\u001b[1;33m   \u001b[0mcall.                                                                                                           \n",
              "\n",
              "\u001b[1mThematic Analysis:\u001b[0m                                                                                                 \n",
              "\n",
              "The most prominent themes throughout the call are:                                                                 \n",
              "\n",
              "\u001b[1;33m • \u001b[0m\u001b[1mAI as a strategic driver:\u001b[0m  Alphabet positions AI as a core driver of its growth and innovation. This is evident \n",
              "\u001b[1;33m   \u001b[0min their investments, product development, and revenue generation strategies.                                   \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mEfficiency and profitability:\u001b[0m  Despite significant investments in AI, Alphabet emphasizes its commitment to     \n",
              "\u001b[1;33m   \u001b[0mefficiency and profitability. This is reflected in their cost management strategies, efforts to optimize        \n",
              "\u001b[1;33m   \u001b[0moperational processes, and focus on monetization.                                                               \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mGrowth and expansion:\u001b[0m  The executives express confidence in Alphabet's future growth potential, particularly in \n",
              "\u001b[1;33m   \u001b[0mareas like YouTube, Cloud, and AI.                                                                              \n",
              "\u001b[1;33m • \u001b[0m\u001b[1mUser experience and innovation:\u001b[0m Alphabet consistently emphasizes its focus on providing a superior user         \n",
              "\u001b[1;33m   \u001b[0mexperience. This is evident in their efforts to enhance search capabilities, personalize advertising, and       \n",
              "\u001b[1;33m   \u001b[0mdevelop innovative products and services.                                                                       \n",
              "\n",
              "\u001b[1mOverall Message and Purpose:\u001b[0m                                                                                       \n",
              "\n",
              "The primary purpose of this earnings call is to communicate Alphabet's financial performance in the first quarter  \n",
              "of 2024 and to provide investors with insights into the company's strategic direction, particularly its commitment \n",
              "to AI as a driver of future growth. The call highlights the company's confident outlook, its focus on efficiency,  \n",
              "and its commitment to providing a compelling user experience. The overarching message is that Alphabet is          \n",
              "well-positioned to leverage the transformative potential of AI to drive continued growth and maintain its          \n",
              "leadership position in the tech industry.                                                                          \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "                    <span style=\"font-weight: bold; text-decoration: underline\">Alphabet's First Quarter 2024 Earnings Conference Call: A Thematic Analysis</span>                    \n",
              "\n",
              "This audio recording is a transcript of an earnings call for Alphabet, the parent company of Google, for the first \n",
              "quarter of 2024. The call features several key executives, including Sundar Pichai and Philip Schindler, and is    \n",
              "structured around opening statements, a Q&amp;A session, and concluding remarks.                                       \n",
              "\n",
              "Here's a breakdown of the call by segments:                                                                        \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 1: Welcome and Introductions (0:00-0:42)</span>                                                                   \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> The call begins with a welcome by the moderator who introduces the participants and explains the call's\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>format.                                                                                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This is a standard opening for a corporate earnings call, setting the stage for the          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>discussion to follow.                                                                                           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> The introduction emphasizes the importance of investor relations and the procedural aspects of the    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>call, creating a formal and structured tone.                                                                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment provides a clear understanding of the call's purpose and the key figures involved in the\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>conversation.                                                                                                   \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 2: Sundar Pichai's Overview (0:42-2:59)</span>                                                                    \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> Sundar Pichai, CEO of Google, highlights the company's strong performance in the first quarter,        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>particularly in Search, YouTube, and Cloud. He then transitions to a broader discussion of Alphabet's AI        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>strategy and its position in the AI landscape.                                                                  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This segment sets the tone for the call by highlighting the importance of AI and its impact  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>on the company's future.                                                                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> Pichai presents a confident and optimistic view of Alphabet's AI capabilities, highlighting its       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>research leadership, infrastructure, and global product footprint. He also emphasizes the company's commitment  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>to efficiency and monetization strategies.                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment lays the foundation for subsequent discussions on specific product areas, such as       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Search, YouTube, and Cloud, by framing them within the overarching context of Alphabet's AI strategy.           \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 3: Philip Schindler's Focus on Advertising and YouTube (2:59-7:08)</span>                                         \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> Philip Schindler, SVP of Ads and Commerce at Google, discusses the company's advertising performance,  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>emphasizing the growth of both Search and YouTube ads. He also highlights the success of AI-driven initiatives, \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>including Smart Bidding and Demand Gen, and the ongoing development of Shorts monetization.                     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This segment delves into the details of Alphabet's revenue generation strategies, showcasing \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>the company's commitment to growth and innovation within its core advertising business.                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> Schindler underscores the importance of AI in optimizing advertising campaigns and reaching targeted  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>audiences. He presents a confident view of the company's future growth prospects, particularly in YouTube, which\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>is positioned as a leader in streaming.                                                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment connects with Pichai's earlier emphasis on AI by showcasing the specific ways in which  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>AI is being implemented to enhance advertising performance. It also highlights the interconnectedness of various\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>product areas, such as YouTube and Search, within Alphabet's broader advertising ecosystem.                     \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 4: Ruth Porat's Financial Overview and Outlook (7:08-12:02)</span>                                                \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> Ruth Porat, CFO of Alphabet, provides a detailed overview of the company's financial performance in the\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>first quarter, highlighting revenue growth, expense management, and operating margins. She also outlines the    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>company's outlook for the rest of the year.                                                                     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This segment provides the financial context for the previous discussions on AI strategy and  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>product performance.                                                                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> Porat emphasizes Alphabet's commitment to profitable growth, showcasing the company's ability to      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>balance aggressive investments with efficient cost management. She highlights the positive impact of AI on      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>revenue growth and the ongoing efforts to optimize the company's expense base.                                  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment further reinforces the importance of AI by highlighting its role in driving revenue     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>growth and improving profitability. It also underscores the company's focus on efficiency and long-term         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>sustainability.                                                                                                 \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 5: Q&amp;A Session (12:02-23:05)</span>                                                                               \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> This segment consists of a series of questions from analysts, focusing on:                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>The impact of AI on Search, particularly monetization strategies and potential changes in search behavior.   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>The drivers of growth in Cloud and the company's strategy for expanding its market share.                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>The company's approach to sports rights, particularly beyond the NFL Sunday Ticket.                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>The significance of the increase in CapEx and its potential implications for future growth.                  \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This segment provides a platform for analysts to probe the details of Alphabet's AI strategy,\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>its financial performance, and its future outlook.                                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> The analysts' questions reflect the current market interest in AI and its implications for Alphabet's \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>business. The responses from executives offer insights into the company's internal thinking and its strategy for\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>navigating the evolving AI landscape.                                                                           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment builds upon the themes established in the opening statements, providing further insights\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>into Alphabet's strategic priorities. It also highlights the importance of collaboration and partnerships in    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>driving innovation and achieving long-term goals.                                                               \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 6: Closing Remarks (23:05-23:49)</span>                                                                           \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Summary:</span> The call concludes with a thank you to the participants and a reminder of the next earnings call date. \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Contextualization:</span> This is a standard closing for a corporate earnings call, concluding the formal conversation.\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Analysis:</span> The closing remarks reiterate the company's commitment to transparency and communication with         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>investors.                                                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Synthesis:</span> This segment provides a sense of closure and reinforces the key messages presented throughout the    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>call.                                                                                                           \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Analysis:</span>                                                                                                 \n",
              "\n",
              "The most prominent themes throughout the call are:                                                                 \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">AI as a strategic driver:</span>  Alphabet positions AI as a core driver of its growth and innovation. This is evident \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>in their investments, product development, and revenue generation strategies.                                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Efficiency and profitability:</span>  Despite significant investments in AI, Alphabet emphasizes its commitment to     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>efficiency and profitability. This is reflected in their cost management strategies, efforts to optimize        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>operational processes, and focus on monetization.                                                               \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Growth and expansion:</span>  The executives express confidence in Alphabet's future growth potential, particularly in \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>areas like YouTube, Cloud, and AI.                                                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">User experience and innovation:</span> Alphabet consistently emphasizes its focus on providing a superior user         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>experience. This is evident in their efforts to enhance search capabilities, personalize advertising, and       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>develop innovative products and services.                                                                       \n",
              "\n",
              "<span style=\"font-weight: bold\">Overall Message and Purpose:</span>                                                                                       \n",
              "\n",
              "The primary purpose of this earnings call is to communicate Alphabet's financial performance in the first quarter  \n",
              "of 2024 and to provide investors with insights into the company's strategic direction, particularly its commitment \n",
              "to AI as a driver of future growth. The call highlights the company's confident outlook, its focus on efficiency,  \n",
              "and its commitment to providing a compelling user experience. The overarching message is that Alphabet is          \n",
              "well-positioned to leverage the transformative potential of AI to drive continued growth and maintain its          \n",
              "leadership position in the tech industry.                                                                          \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Features from Video Files"
      ],
      "metadata": {
        "id": "YubNzOHmSWel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_uri_list_video = get_gcs_uri_list(bucket,production_data,'.mp4')"
      ],
      "metadata": {
        "id": "Xgihj9N7K5YK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_uri_list_video[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_iH5g8LK6JY",
        "outputId": "31c91390-5fb4-4325-80d2-b10fb47cf94b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand new emojis  Testing Gemini.mp4',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand your outfit  Testing Gemini.mp4',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Converting images into code with AI  Testing Gemini.mp4',\n",
              " 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Finding connections with AI  Testing Gemini.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gcs_uri_list_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVOIIEwNLitw",
        "outputId": "93681e1b-ac88-4ca4-97e9-269e450514d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "max_concurrent = 4\n",
        "video_description_extraction_prompt = \"\"\"Transcribe and analyze the video, intelligently segmenting it based on shifts in topic, focus, or narrative progression.\n",
        "For each identified segment:\n",
        "**Concise Summary**: Distill the core theme or message in 1-2 sentences.\n",
        "**Thematic Context**: How does this segment contribute to the overarching narrative or argument?\n",
        "**Critical Analysis**: Delve into the segment's implications, perspectives presented, and potential biases.\n",
        "**Connections**: Link this segment to other parts of the video, revealing patterns and relationships.\n",
        "\n",
        "Conclude by synthesizing the video's main themes, their interconnections, and the overarching purpose or message.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "final_response_list_video = await batch_and_profile(gcs_uri_list_video,\n",
        "                                                    video_description_extraction_prompt,\n",
        "                                                    \"video/mp4\",\n",
        "                                                    batch_size, max_concurrent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xImffMxQPJPL",
        "outputId": "0f1b1b01-c774-4f22-c2e2-e5021a36bdea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Something failed, retrying\n",
            "500 Internal error encountered.\n",
            "Batch size: 5\n",
            "Elapsed time: 47.86 seconds\n",
            "Initial memory usage: 643.84 MB\n",
            "Final memory usage: 646.67 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata_flash = pd.DataFrame([gcs_uri_list_video, final_response_list_video]).T\n",
        "video_metadata_flash.columns = ['video_gcs', 'video_description']\n",
        "video_metadata_flash.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "BZGKGD8OUMh9",
        "outputId": "baba44d1-4375-4a8d-8c48-30a559061050"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           video_gcs  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "                                   video_description  \n",
              "0  ## Video Transcription and Analysis: Can Gemin...  \n",
              "1  ## Video Analysis: Can Gemini Understand Outfi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfee76dc-53bc-4fbe-91cc-e694d30e42f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_gcs</th>\n",
              "      <th>video_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Video Transcription and Analysis: Can Gemin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Video Analysis: Can Gemini Understand Outfi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfee76dc-53bc-4fbe-91cc-e694d30e42f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfee76dc-53bc-4fbe-91cc-e694d30e42f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfee76dc-53bc-4fbe-91cc-e694d30e42f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83b72f61-2dda-4d03-818c-d4d0a9ba1a15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83b72f61-2dda-4d03-818c-d4d0a9ba1a15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83b72f61-2dda-4d03-818c-d4d0a9ba1a15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "video_metadata_flash",
              "summary": "{\n  \"name\": \"video_metadata_flash\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"video_gcs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand new emojis  Testing Gemini.mp4\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand your outfit  Testing Gemini.mp4\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Multimodal prompting with a 44-minute movie  Gemini 15 Pro Demo.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"## Video Transcription and Analysis: Can Gemini Understand Unusual Emojis?\\n\\n**Segment 1 (0:00-0:29)**\\n\\n**Concise Summary**: The video introduces Gemini, a multimodal AI model, and tests its ability to recognize unusual emojis created by combining existing ones.\\n\\n**Thematic Context**: This segment establishes the video's primary theme: exploring Gemini's understanding of visual information beyond text.\\n\\n**Critical Analysis**: The use of emojis as a testing ground highlights Gemini's potential to analyze complex visual concepts. However, the context and limitations of the test remain unclear.\\n\\n**Connections**: This segment directly transitions into the next segment where Gemini is challenged to explain its reasoning behind the emoji identification.\\n\\n**Segment 2 (0:29-0:47)**\\n\\n**Concise Summary**: Gemini correctly identifies the original emojis used to create the unusual one, demonstrating its visual recognition capabilities.\\n\\n**Thematic Context**: This segment further reinforces the video's focus on Gemini's visual comprehension abilities.\\n\\n**Critical Analysis**: While Gemini identifies the emojis correctly, its reasoning remains superficial, focusing primarily on shape and color. This suggests potential limitations in understanding complex symbolism.\\n\\n**Connections**: This segment flows smoothly into the next, where Gemini is tasked with giving a name and tagline to the unusual emoji.\\n\\n**Segment 3 (0:47-1:05)**\\n\\n**Concise Summary**: Gemini demonstrates its creative ability by giving names and taglines to three unusual emojis, showcasing its understanding of visual concepts.\\n\\n**Thematic Context**: This segment highlights Gemini's creative application of visual analysis, showcasing its potential beyond simple identification.\\n\\n**Critical Analysis**: Gemini's responses are witty and demonstrate a basic grasp of the emoji's visual features. However, it remains unclear if Gemini understands the deeper meanings associated with these emojis.\\n\\n**Connections**: This segment concludes the video by showcasing Gemini's unique abilities and promoting further exploration of its capabilities.\\n\\n**Overall Synthesis**:\\n\\nThe video explores the abilities of Gemini, a multi-modal AI, by testing its understanding of unusual emojis. It demonstrates Gemini's proficiency in recognizing visual combinations and generating creative interpretations. However, the video raises questions about Gemini's ability to understand deeper meanings and symbolic associations within visual elements. The overall purpose is to introduce Gemini as a promising AI model with exciting potential for interpreting and engaging with visual information. \\n\",\n          \"## Video Analysis: Can Gemini Understand Outfits?\\n\\n**Segment 1: 0:00-0:19**\\n\\n**Concise Summary:** The video begins by testing Gemini's ability to understand the context of a simple outfit, a blue puffer jacket. \\n\\n**Thematic Context:** This segment introduces the core concept of the video: exploring Gemini's understanding of visual elements, specifically in the context of clothing.\\n\\n**Critical Analysis:** This segment sets the stage for a light-hearted yet insightful investigation into Gemini's capabilities. The question \\\"what is someone wearing this best dressed to do?\\\"  hints at the potential for Gemini to not just identify objects, but also deduce their purpose and the actions they imply.\\n\\n**Connections:** This segment directly connects to the final scene, showcasing a collection of various visual elements and poses the question \\\"Can Gemini understand outfits?\\\"  This signifies that the video will explore Gemini's understanding of outfits beyond just one example.\\n\\n\\n**Segment 2: 0:20-0:39**\\n\\n**Concise Summary:** The video further tests Gemini by adding a space helmet and a saxophone to the outfit, prompting Gemini to explain the purpose of the ensemble.\\n\\n**Thematic Context:** This segment expands on the previous one, testing Gemini's ability to understand outfits with multiple elements and interpret their combined meaning.\\n\\n**Critical Analysis:** By adding increasingly complex and absurd elements to the outfit, the video probes Gemini's capacity to navigate and understand diverse scenarios. The humorous response \\\"To boldly go where no one has gone before... and play some jazz\\\" demonstrates Gemini's ability to generate creative and unexpected interpretations.\\n\\n**Connections:** This segment reinforces the connection to the final scene, showcasing a collection of various visual elements and poses the question \\\"Can Gemini understand outfits?\\\"  This signifies that the video will explore Gemini's understanding of outfits beyond just one example.\\n\\n\\n**Segment 3: 0:39-0:44**\\n\\n**Concise Summary:** The video concludes with a montage of diverse visual elements, showcasing Gemini's various capabilities while emphasizing its ability to \\\"understand outfits.\\\"\\n\\n**Thematic Context:** This segment serves as a concluding statement, offering a broader scope of Gemini's potential applications.\\n\\n**Critical Analysis:** The final scene presents a wide range of visual elements, showcasing Gemini's versatility and ability to process different types of information. The video implicitly suggests that Gemini's capabilities extend beyond clothing analysis and could have applications in various visual domains.\\n\\n**Connections:** This segment directly ties back to the initial segments, showcasing Gemini's growing understanding of outfits. The concluding statement \\\"Stay tuned for more visual tests soon\\\" suggests that the video is only a glimpse into the vast potential of Gemini's capabilities.\\n\\n**Synthesizing Main Themes:**\\n\\nThe video explores the exciting possibilities of Gemini, Google's new multimodal AI, in understanding and interpreting visual information. It highlights Gemini's ability to analyze objects, comprehend their context, and generate creative responses based on these visual cues. The video effectively conveys that Gemini is not just a language model but a multimodal AI with the potential to revolutionize our interaction with visual information. The overarching message is that Gemini's capacity for visual understanding holds immense promise for future applications in diverse fields.\\n\",\n          \"## Video Transcription and Analysis: Gemini 1.5 Pro Long Context Understanding\\n\\n**Segment 1: 0:00 - 0:18**\\n**Concise Summary**: The video introduces Gemini 1.5 Pro, a new language model with an experimental long context understanding feature.\\n**Thematic Context**: This sets the stage for the demonstration, highlighting the key feature of the model.\\n**Critical Analysis**: The term \\\"experimental\\\" suggests the feature is under development and may have limitations. The use of tokens as a measure of context raises questions about how this metric relates to human understanding.\\n**Connections**:  This segment directly connects to the subsequent demonstration by specifying the capabilities being showcased.\\n\\n**Segment 2: 0:18 - 0:59**\\n**Concise Summary**: The video demonstrates the model's ability to understand and analyze a 44-minute Buster Keaton film by accurately locating a specific event and providing relevant information about it.\\n**Thematic Context**: This segment provides a concrete example of the model's long context understanding.\\n**Critical Analysis**: The demonstration showcases the model's ability to process complex information, potentially suggesting its potential for research and analysis tasks. However, the video doesn't address the model's limitations, like potential biases or difficulties in nuanced understanding.\\n**Connections**:  This segment builds on the introduction by providing a visual and interactive demonstration of the long context feature.\\n\\n**Segment 3: 1:00 - 1:44**\\n**Concise Summary**: The video demonstrates the model's ability to analyze a simple drawing and locate a corresponding scene within a video.\\n**Thematic Context**: This segment expands on the model's multimodal capabilities, showing its ability to understand both visual and textual information.\\n**Critical Analysis**: This demonstration highlights the model's potential for creative and intuitive interaction, but it doesn't explore the potential for misinterpretation or difficulties in understanding complex visual concepts.\\n**Connections**: This segment builds on the previous one, showcasing further applications of the long context feature in a multimodal setting.\\n\\n**Segment 4: 1:44 - 1:58**\\n**Concise Summary**: The video concludes by highlighting the model's capacity for handling up to 1 million multimodal tokens.\\n**Thematic Context**: This segment summarizes the key takeaway of the demonstration, emphasizing the model's impressive processing capabilities.\\n**Critical Analysis**: The statement about multimodal tokens is suggestive of the model's potential but lacks specific details about how the model handles different types of information and how it scales with increasing context.\\n**Connections**: This segment concludes the demonstration by emphasizing the potential of the Gemini 1.5 Pro model and providing a call to action to learn more.\\n\\n**Synthesis**:\\n\\nThe video showcases Google's Gemini 1.5 Pro language model's new experimental feature: long context understanding. Through demonstrations involving both a film and a simple drawing, the video highlights the model's ability to process vast amounts of data and accurately locate specific events. \\n\\nThe video primarily focuses on presenting the model's capabilities, emphasizing its potential for various applications. However, it doesn't address potential limitations like biases, misinterpretations, or challenges in handling complex and nuanced information. The overall purpose of the video seems to be to generate excitement and interest in the potential of this new technology. \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rich_Markdown(video_metadata_flash.iloc[5]['video_description'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WuSgt57UQeRe",
        "outputId": "b449085e-020b-4bc7-fe57-5e917c117bc3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "                                   \u001b[1;4mGoogle's Gemini AI: A Multimodal Breakthrough\u001b[0m                                   \n",
              "\n",
              "\u001b[1mSegment 1 (0:00-0:26)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m: The video begins by establishing Google's long-standing mission to organize the world's           \n",
              "information and make it accessible. However, the speaker acknowledges that the increasing complexity of information\n",
              "necessitates a groundbreaking advancement.                                                                         \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m: This segment introduces the video's core argument: the need for a new approach to AI to address  \n",
              "the growing challenge of organizing and understanding complex information.                                         \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m: While presenting Google's mission as timeless, the segment focuses on the \"problem\" getting     \n",
              "harder, implying that their past efforts are inadequate. It sets the stage for a solution-oriented narrative.      \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment connects to the later discussions about Gemini's capabilities and how it addresses the   \n",
              "limitations of past AI models.                                                                                     \n",
              "\n",
              "\u001b[1mSegment 2 (0:27-1:35)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m: The video introduces Gemini as a multimodal AI model, capable of understanding and interacting    \n",
              "with information in various forms, including text, code, audio, images, and video.                                 \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m: This segment introduces the main innovation – Gemini's multimodality – as a key differentiator   \n",
              "from previous AI models.                                                                                           \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m: This segment highlights the potential of Gemini to handle real-world information in its diverse \n",
              "forms, suggesting a more nuanced and comprehensive understanding compared to text-only AI models. However, it      \n",
              "doesn't address the ethical implications of this capability.                                                       \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment sets the stage for further explanations of Gemini's capabilities and the specific        \n",
              "challenges it addresses.                                                                                           \n",
              "\n",
              "\u001b[1mSegment 3 (1:36-2:01)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m:  The speaker emphasizes Gemini's versatility, highlighting its performance on various benchmarks  \n",
              "and its ability to rival human experts in multiple domains.                                                        \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m: This segment showcases Gemini's impressive performance, building a case for its significance as a\n",
              "breakthrough in AI.                                                                                                \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m:  The segment emphasizes Gemini's performance metrics, potentially suggesting that its capability\n",
              "is the primary measure of its success. It doesn't discuss the potential for human biases in these benchmarks.      \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment reinforces the need for a new approach to AI, demonstrated by Gemini's exceptional       \n",
              "abilities compared to previous models.                                                                             \n",
              "\n",
              "\u001b[1mSegment 4 (2:02-2:48)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m: The video shifts focus to the broader implications of Gemini, emphasizing its potential to        \n",
              "transform products and industries while raising new ethical questions.                                             \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m: This segment expands the conversation beyond technical capabilities, highlighting the societal   \n",
              "and ethical implications of this powerful new technology.                                                          \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m: This segment acknowledges the significant impact of Gemini, but primarily focuses on its        \n",
              "potential benefits. The ethical implications are presented as a separate consideration, potentially underplaying   \n",
              "their importance.                                                                                                  \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment connects to the earlier discussion about making AI helpful for everyone, highlighting the\n",
              "potential of Gemini to achieve this while needing careful consideration of its ethical use.                        \n",
              "\n",
              "\u001b[1mSegment 5 (2:49-3:34)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m:  The video emphasizes Google's commitment to responsible AI development and the implementation of \n",
              "safeguards to mitigate potential harms.                                                                            \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m:  This segment addresses the ethical concerns raised earlier, outlining Google's approach to      \n",
              "developing Gemini responsibly.                                                                                     \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m: This segment presents Google's approach to responsible AI as proactive and comprehensive, using \n",
              "terms like \"bold\" and \"proactive\" to portray their commitment. It doesn't delve into the specific challenges of    \n",
              "ensuring responsible use in various contexts.                                                                      \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment connects to the previous discussion about the potential impact of Gemini, attempting to  \n",
              "balance the excitement with concerns about its responsible development.                                            \n",
              "\n",
              "\u001b[1mSegment 6 (3:35-4:34)\u001b[0m                                                                                              \n",
              "\n",
              "\u001b[1mConcise Summary\u001b[0m: The video concludes with a call to action, emphasizing Google's role in driving AI advancements   \n",
              "and its vision for a world empowered by helpful and accessible information.                                        \n",
              "\n",
              "\u001b[1mThematic Context\u001b[0m:  This segment summarizes the video's overarching message: Gemini represents a significant        \n",
              "breakthrough in AI with the potential to empower individuals and create a world with more knowledge and access to  \n",
              "information.                                                                                                       \n",
              "\n",
              "\u001b[1mCritical Analysis\u001b[0m: This segment presents a positive and optimistic vision of the future powered by AI. It doesn't  \n",
              "address potential inequalities in access to information or the potential for AI to perpetuate existing societal    \n",
              "biases.                                                                                                            \n",
              "\n",
              "\u001b[1mConnections\u001b[0m: This segment brings together all the video's key themes, highlighting the potential of Gemini to      \n",
              "realize Google's mission and contribute to a better future while needing careful and responsible development.      \n",
              "\n",
              "\u001b[1mOverarching Themes\u001b[0m: The video focuses on Google's commitment to advancing AI and its belief that Gemini represents \n",
              "a significant breakthrough. It highlights the potential for Gemini to provide more knowledge and information access\n",
              "to everyone while acknowledging the need for responsible development and ethical considerations.                   \n",
              "\n",
              "\u001b[1mOverarching Message\u001b[0m:  This video serves as a promotional piece for Google's Gemini AI, highlighting its            \n",
              "capabilities, potential impact, and commitment to responsible development. It ultimately aims to generate          \n",
              "excitement and promote the adoption of this new technology while emphasizing Google's leadership in the field.     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "                                   <span style=\"font-weight: bold; text-decoration: underline\">Google's Gemini AI: A Multimodal Breakthrough</span>                                   \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 1 (0:00-0:26)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>: The video begins by establishing Google's long-standing mission to organize the world's           \n",
              "information and make it accessible. However, the speaker acknowledges that the increasing complexity of information\n",
              "necessitates a groundbreaking advancement.                                                                         \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>: This segment introduces the video's core argument: the need for a new approach to AI to address  \n",
              "the growing challenge of organizing and understanding complex information.                                         \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>: While presenting Google's mission as timeless, the segment focuses on the \"problem\" getting     \n",
              "harder, implying that their past efforts are inadequate. It sets the stage for a solution-oriented narrative.      \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment connects to the later discussions about Gemini's capabilities and how it addresses the   \n",
              "limitations of past AI models.                                                                                     \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 2 (0:27-1:35)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>: The video introduces Gemini as a multimodal AI model, capable of understanding and interacting    \n",
              "with information in various forms, including text, code, audio, images, and video.                                 \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>: This segment introduces the main innovation – Gemini's multimodality – as a key differentiator   \n",
              "from previous AI models.                                                                                           \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>: This segment highlights the potential of Gemini to handle real-world information in its diverse \n",
              "forms, suggesting a more nuanced and comprehensive understanding compared to text-only AI models. However, it      \n",
              "doesn't address the ethical implications of this capability.                                                       \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment sets the stage for further explanations of Gemini's capabilities and the specific        \n",
              "challenges it addresses.                                                                                           \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 3 (1:36-2:01)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>:  The speaker emphasizes Gemini's versatility, highlighting its performance on various benchmarks  \n",
              "and its ability to rival human experts in multiple domains.                                                        \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>: This segment showcases Gemini's impressive performance, building a case for its significance as a\n",
              "breakthrough in AI.                                                                                                \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>:  The segment emphasizes Gemini's performance metrics, potentially suggesting that its capability\n",
              "is the primary measure of its success. It doesn't discuss the potential for human biases in these benchmarks.      \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment reinforces the need for a new approach to AI, demonstrated by Gemini's exceptional       \n",
              "abilities compared to previous models.                                                                             \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 4 (2:02-2:48)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>: The video shifts focus to the broader implications of Gemini, emphasizing its potential to        \n",
              "transform products and industries while raising new ethical questions.                                             \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>: This segment expands the conversation beyond technical capabilities, highlighting the societal   \n",
              "and ethical implications of this powerful new technology.                                                          \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>: This segment acknowledges the significant impact of Gemini, but primarily focuses on its        \n",
              "potential benefits. The ethical implications are presented as a separate consideration, potentially underplaying   \n",
              "their importance.                                                                                                  \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment connects to the earlier discussion about making AI helpful for everyone, highlighting the\n",
              "potential of Gemini to achieve this while needing careful consideration of its ethical use.                        \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 5 (2:49-3:34)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>:  The video emphasizes Google's commitment to responsible AI development and the implementation of \n",
              "safeguards to mitigate potential harms.                                                                            \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>:  This segment addresses the ethical concerns raised earlier, outlining Google's approach to      \n",
              "developing Gemini responsibly.                                                                                     \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>: This segment presents Google's approach to responsible AI as proactive and comprehensive, using \n",
              "terms like \"bold\" and \"proactive\" to portray their commitment. It doesn't delve into the specific challenges of    \n",
              "ensuring responsible use in various contexts.                                                                      \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment connects to the previous discussion about the potential impact of Gemini, attempting to  \n",
              "balance the excitement with concerns about its responsible development.                                            \n",
              "\n",
              "<span style=\"font-weight: bold\">Segment 6 (3:35-4:34)</span>                                                                                              \n",
              "\n",
              "<span style=\"font-weight: bold\">Concise Summary</span>: The video concludes with a call to action, emphasizing Google's role in driving AI advancements   \n",
              "and its vision for a world empowered by helpful and accessible information.                                        \n",
              "\n",
              "<span style=\"font-weight: bold\">Thematic Context</span>:  This segment summarizes the video's overarching message: Gemini represents a significant        \n",
              "breakthrough in AI with the potential to empower individuals and create a world with more knowledge and access to  \n",
              "information.                                                                                                       \n",
              "\n",
              "<span style=\"font-weight: bold\">Critical Analysis</span>: This segment presents a positive and optimistic vision of the future powered by AI. It doesn't  \n",
              "address potential inequalities in access to information or the potential for AI to perpetuate existing societal    \n",
              "biases.                                                                                                            \n",
              "\n",
              "<span style=\"font-weight: bold\">Connections</span>: This segment brings together all the video's key themes, highlighting the potential of Gemini to      \n",
              "realize Google's mission and contribute to a better future while needing careful and responsible development.      \n",
              "\n",
              "<span style=\"font-weight: bold\">Overarching Themes</span>: The video focuses on Google's commitment to advancing AI and its belief that Gemini represents \n",
              "a significant breakthrough. It highlights the potential for Gemini to provide more knowledge and information access\n",
              "to everyone while acknowledging the need for responsible development and ethical considerations.                   \n",
              "\n",
              "<span style=\"font-weight: bold\">Overarching Message</span>:  This video serves as a promotional piece for Google's Gemini AI, highlighting its            \n",
              "capabilities, potential impact, and commitment to responsible development. It ultimately aims to generate          \n",
              "excitement and promote the adoption of this new technology while emphasizing Google's leadership in the field.     \n",
              "</pre>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# audio_metadata_flash.to_csv(\"audio_metadata_flash.csv\")"
      ],
      "metadata": {
        "id": "Zi6wFn3UbPdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# video_metadata_flash.to_csv(\"video_metadata_flash.csv\")"
      ],
      "metadata": {
        "id": "K4buo4VwbPZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting/Chunking the text"
      ],
      "metadata": {
        "id": "zIJW73Q1U5dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "uuid.uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCE4PIgy27HV",
        "outputId": "1399b77e-8dad-46ce-fa90-a649e76c7e87"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('1928f6d0-8aeb-4cc6-acbe-9ce0c88d02a6')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_unique_uuids(dataframes):\n",
        "    \"\"\"Assigns unique UUIDs to each row of multiple dataframes.\n",
        "\n",
        "    Args:\n",
        "        dataframes (list): A list of pandas DataFrames.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of DataFrames with the 'uid' column added.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    result_dataframes = []\n",
        "    for df in dataframes:\n",
        "        df['uid'] = df.apply(lambda row: str(uuid.uuid4().hex), axis=1)\n",
        "        result_dataframes.append(df)\n",
        "\n",
        "    return result_dataframes\n",
        "\n",
        "def split_text_into_chunks(df, text_column, chunk_size):\n",
        "    \"\"\"Splits text into chunks of specified size, preserving other column values and adding a chunk number column.\"\"\"\n",
        "\n",
        "    # Create a list of new dataframes, one for each chunk\n",
        "    new_dfs = []\n",
        "    for _, row in df.iterrows():\n",
        "        text_chunks = [row[text_column][i:i + chunk_size] for i in range(0, len(row[text_column]), chunk_size)]\n",
        "        for chunk_index, chunk in enumerate(text_chunks):\n",
        "            new_row = row.copy()  # Copy all other columns\n",
        "            new_row[text_column] = chunk\n",
        "            new_row['chunk_number'] = chunk_index + 1  # Add chunk number starting from 1\n",
        "            new_dfs.append(pd.DataFrame([new_row]))\n",
        "\n",
        "    return pd.concat(new_dfs, ignore_index=True)  # Combine into single dataframe"
      ],
      "metadata": {
        "id": "KppC2sVgFkxt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Step 2 [Why do we still do chunking? Explain ----\n",
        "# 1) show the token count\n",
        "# 2) reduce noise while search  ]\n",
        "# latency and cost consideriation - you can still do that, but would it make sense\n",
        "# Out of 5M token \"information\" -> you would still want to makes ure that the 1M that you send are the most relevant 1M\n",
        "# Chunking the Text to smaller size to make precise match with queries\n",
        "\n",
        "chunk_size = 500\n",
        "extracted_text_chunk_df = split_text_into_chunks(pdf_metadata_flash[~pdf_metadata_flash['text'].isnull()], 'text', chunk_size)\n",
        "image_metadata_chunk_df = split_text_into_chunks(image_metadata_flash_final, 'image_description', chunk_size)\n",
        "video_metadata_chunk_df = split_text_into_chunks(video_metadata_flash, 'video_description', chunk_size)\n",
        "audio_metadata_chunk_df = split_text_into_chunks(audio_metadata_flash, 'audio_description', chunk_size)"
      ],
      "metadata": {
        "id": "BjbVrF3LbPWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb666eae-94ea-411f-d5cc-76e084caa787"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20 s, sys: 263 ms, total: 20.3 s\n",
            "Wall time: 21.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(extracted_text_chunk_df,\n",
        "image_metadata_chunk_df,\n",
        " video_metadata_chunk_df,\n",
        " audio_metadata_chunk_df) = assign_unique_uuids([extracted_text_chunk_df,\n",
        "                                                image_metadata_chunk_df,\n",
        "                                                video_metadata_chunk_df,\n",
        "                                                audio_metadata_chunk_df],\n",
        "                                               )"
      ],
      "metadata": {
        "id": "wR83ECIn2I8A"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text_chunk_df.head()"
      ],
      "metadata": {
        "id": "IRID-4QpbPTS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "f257f114-6f3e-4550-d8f8-dab0ec5bfda5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  text_type                                          file_name  \\\n",
              "0  blogpost   Google announces the Coalition for Secure AI.pdf   \n",
              "1  blogpost   Google announces the Coalition for Secure AI.pdf   \n",
              "2  blogpost   Google announces the Coalition for Secure AI.pdf   \n",
              "3  blogpost  Google Gemini updates_ Flash 1.5, Gemma 2 and ...   \n",
              "4  blogpost  Google Gemini updates_ Flash 1.5, Gemma 2 and ...   \n",
              "\n",
              "                                            gcs_path  page_number  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "2  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "3  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "4  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "\n",
              "                                                text  image_available  \\\n",
              "0  Additionally, CoSAI will collaborate with orga...            False   \n",
              "1  ll to help organizations securely implement, t...            False   \n",
              "2  \\nSafety & Security  AI8/13/24, 8:09 PM Google...            False   \n",
              "3  1.5 Pro can now follow increasingly complex an...            False   \n",
              "4  .5 Pro can now reason\\nacross image and audio ...            False   \n",
              "\n",
              "   image_counter image_gcs_path image_size  chunk_number  \\\n",
              "0            NaN           None       None             1   \n",
              "1            NaN           None       None             2   \n",
              "2            NaN           None       None             3   \n",
              "3            NaN           None       None             1   \n",
              "4            NaN           None       None             2   \n",
              "\n",
              "                                uid  \n",
              "0  91eb9e70cc47499ea0e66c7bac787471  \n",
              "1  9e1cbaf288584e13b5cdd2ef505da1fb  \n",
              "2  6b2aa4129b1649e9aeadea99037dde31  \n",
              "3  96c064d349d441a7bdca3f95b839ebe8  \n",
              "4  632d6d7b82be456b8df44fd7dd6dda1e  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04ed50a8-4cca-4851-ba04-9ad6f2eb153f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "      <th>chunk_number</th>\n",
              "      <th>uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google announces the Coalition for Secure AI.pdf</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Additionally, CoSAI will collaborate with orga...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>91eb9e70cc47499ea0e66c7bac787471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google announces the Coalition for Secure AI.pdf</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>ll to help organizations securely implement, t...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>9e1cbaf288584e13b5cdd2ef505da1fb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google announces the Coalition for Secure AI.pdf</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>\\nSafety &amp; Security  AI8/13/24, 8:09 PM Google...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>6b2aa4129b1649e9aeadea99037dde31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google Gemini updates_ Flash 1.5, Gemma 2 and ...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>1.5 Pro can now follow increasingly complex an...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>96c064d349d441a7bdca3f95b839ebe8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Google Gemini updates_ Flash 1.5, Gemma 2 and ...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>.5 Pro can now reason\\nacross image and audio ...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>632d6d7b82be456b8df44fd7dd6dda1e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04ed50a8-4cca-4851-ba04-9ad6f2eb153f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04ed50a8-4cca-4851-ba04-9ad6f2eb153f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04ed50a8-4cca-4851-ba04-9ad6f2eb153f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59af8066-dfde-428c-9ab9-96b5120b493a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59af8066-dfde-428c-9ab9-96b5120b493a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59af8066-dfde-428c-9ab9-96b5120b493a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "extracted_text_chunk_df",
              "summary": "{\n  \"name\": \"extracted_text_chunk_df\",\n  \"rows\": 10069,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"earning_transcript\",\n          \"annual_report\",\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"20221025-alphabet-10q.pdf\",\n          \"20210203-alphabet-10k.pdf\",\n          \"2021_Q4_Earnings_Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/quaterly_report/20221025-alphabet-10q.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2020/quaterly_report/20210203-alphabet-10k.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2021/earning_transcript/2021_Q4_Earnings_Transcript.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 1,\n        \"max\": 136,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          74,\n          46,\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9605,\n        \"samples\": [\n          \"Built using the Arm Neoverse\\u2122 V2 CPU, Axion\\nprocessors deliver giant leaps in pe\\u0000ormance for\\ngeneral-purpose workloads like web and app\\nservers, containerized microservices, open-\\nsource databases, in-memory caches, data\\nanalytics engines, media processing, CPU-based\\nAI training and inferencing, and more.\\u00a0\\nAxion is underpinned by Titanium, a system of\\npurpose-built custom silicon microcontrollers and\\ntiered scale-out o\\u0000oads. Titanium o\\u0000oads take\\ncare of pla\\u0000orm operations like networking and\\nsec\",\n          \"rdance with Alphabet\\u2019 sequity\\ngrant practice andmethodology ,thegrant willbemade onthefirstWednesday ofMay,andthenumber ofGSUs\\ncomprising thegrant willbecalculated bydividing theequity award amount bytheaverage closing price of\\nAlphabet\\u2019 sClass Ccapital stock during themonth ofApril 2020. Theaward willvest 2/16th onJune 25th, 2020, and\\n1/16th quarterly thereafter until fully vested inDecember 2023, subject tocontinued employment. Upon vesting,\\neach GSU willentitle Ms.Porat toreceive oneshare ofA\",\n          \"nd newer advertising \\nformats . The margins from these channels and newer products have generally been lower than those from traditional \\ndesktop search. Additionally, as the market for a particular device type or modality matures, our advertising revenues \\nmay be affected.  For example, growth in the global smartphone market has slowed due to various factors, including \\nincreased market saturation in developed countries, which can affect our mobile advertising revenues.\\nWe expect TAC paid to ou\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.682197423160196,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          9.0,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page27_mepier.jpeg\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page17_vvhblj.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          [\n            643,\n            468\n          ],\n          [\n            465,\n            520\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10069,\n        \"samples\": [\n          \"46c9cac70fdf4283b3c68d36b172ac5f\",\n          \"5e48e6e412ea4a059d17db8e02f1e3c1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_metadata_chunk_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "6X8C6txawoEe",
        "outputId": "4dd533f8-c7ee-4298-9d20-b936318aae95"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  text_type                                          file_name  \\\n",
              "0  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "1  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "2  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "3  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "4  blogpost  Goodput metric as measure of ML productivity _...   \n",
              "\n",
              "                                            gcs_path  page_number  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...            3   \n",
              "2  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "3  gs://mlops-for-genai/multimodal-finanace-qa/da...            4   \n",
              "4  gs://mlops-for-genai/multimodal-finanace-qa/da...            5   \n",
              "\n",
              "                                                text  image_available  \\\n",
              "0  Productivity Goodput, to measure this e\u0000ciency...             True   \n",
              "1  Productivity Goodput, to measure this e\u0000ciency...             True   \n",
              "2  how you can measure and maximize runtime for\\n...             True   \n",
              "3  how you can measure and maximize runtime for\\n...             True   \n",
              "4  As indicated in the diagram above, AI\\nHyperco...             True   \n",
              "\n",
              "   image_counter                                     image_gcs_path  \\\n",
              "0            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "1            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "2            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "3            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "4            1.0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "    image_size                                  image_description  \\\n",
              "0  (2200, 924)  The image depicts a diagram illustrating the t...   \n",
              "1  (2200, 924)  odput:** Measures the fraction of peak availab...   \n",
              "2  (2200, 941)  The diagram depicts the elements of ML Product...   \n",
              "3  (2200, 941)  are layer contains Compute (GPUs, TPUs), Stora...   \n",
              "4  (2000, 708)  The image is a timeline diagram illustrating t...   \n",
              "\n",
              "   chunk_number                               uid  \n",
              "0             1  b90f4e1ef996437bae36eb24a17f149f  \n",
              "1             2  d565e9515a794299b659a17683b295a7  \n",
              "2             1  3266e9efa28f40af8a13b61bc2f9ddc7  \n",
              "3             2  38e7b9f6e0784345a462ae01a1e79e46  \n",
              "4             1  2756487575cb4d21a59829e2a776f4db  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54890df4-6eff-45d5-8de9-2c593a084d33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_type</th>\n",
              "      <th>file_name</th>\n",
              "      <th>gcs_path</th>\n",
              "      <th>page_number</th>\n",
              "      <th>text</th>\n",
              "      <th>image_available</th>\n",
              "      <th>image_counter</th>\n",
              "      <th>image_gcs_path</th>\n",
              "      <th>image_size</th>\n",
              "      <th>image_description</th>\n",
              "      <th>chunk_number</th>\n",
              "      <th>uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Productivity Goodput, to measure this e\u0000ciency...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 924)</td>\n",
              "      <td>The image depicts a diagram illustrating the t...</td>\n",
              "      <td>1</td>\n",
              "      <td>b90f4e1ef996437bae36eb24a17f149f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>3</td>\n",
              "      <td>Productivity Goodput, to measure this e\u0000ciency...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 924)</td>\n",
              "      <td>odput:** Measures the fraction of peak availab...</td>\n",
              "      <td>2</td>\n",
              "      <td>d565e9515a794299b659a17683b295a7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>how you can measure and maximize runtime for\\n...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 941)</td>\n",
              "      <td>The diagram depicts the elements of ML Product...</td>\n",
              "      <td>1</td>\n",
              "      <td>3266e9efa28f40af8a13b61bc2f9ddc7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>4</td>\n",
              "      <td>how you can measure and maximize runtime for\\n...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2200, 941)</td>\n",
              "      <td>are layer contains Compute (GPUs, TPUs), Stora...</td>\n",
              "      <td>2</td>\n",
              "      <td>38e7b9f6e0784345a462ae01a1e79e46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blogpost</td>\n",
              "      <td>Goodput metric as measure of ML productivity _...</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>5</td>\n",
              "      <td>As indicated in the diagram above, AI\\nHyperco...</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>(2000, 708)</td>\n",
              "      <td>The image is a timeline diagram illustrating t...</td>\n",
              "      <td>1</td>\n",
              "      <td>2756487575cb4d21a59829e2a776f4db</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54890df4-6eff-45d5-8de9-2c593a084d33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54890df4-6eff-45d5-8de9-2c593a084d33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54890df4-6eff-45d5-8de9-2c593a084d33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a058b546-7ef5-4d8a-a671-3cd32c2a8ea9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a058b546-7ef5-4d8a-a671-3cd32c2a8ea9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a058b546-7ef5-4d8a-a671-3cd32c2a8ea9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "image_metadata_chunk_df",
              "summary": "{\n  \"name\": \"image_metadata_chunk_df\",\n  \"rows\": 171,\n  \"fields\": [\n    {\n      \"column\": \"text_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"annual_report\",\n          \"blogpost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gcs_path\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Goodput metric as measure of ML productivity _ Google Cloud Blog.pdf\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/blogpost/Introducing Google\\u2019s new Arm-based CPU _ Google Cloud Blog.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 2,\n        \"max\": 33,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          31,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 63,\n        \"samples\": [\n          \"30\\u201cWe just don\\u2019t have \\nthe same climate we \\nused to. Technology \\nallows us to continue \\nto push forward so the \\nvineyards will outlast us.\\u201d\\n\\u2013 Riggs Lokka, Emeritus Vineyards\\nAdam Koeppel and Tyler Locke co-founded Agrology \\nto help farmers adapt to changing climates. Using \\nGoogle Cloud with TensorFlow, public benefit \\ncorporation Agrology runs machine learning models \\non sensor data to provide predictive insights for growers like multigeneration Emeritus Vineyards.\",\n          \"25\\nYear in Review 2022We also continued to bring improvements to our \\nproducts to help them work better for everyone. For people with disabilities, speech recognition is an increasingly important dimension of how people interact with technology, and in 2022, we joined the Speech Accessibility Project, a collaboration between researchers at the University of Illinois Urbana-Champaign and five technology companies. The university is working with advocacy groups, like Team Gleason and the Davis Phinney Foundation, to create data sets of impaired speech that can help accelerate improvements to automated speech recognition (ASR), a key step toward supporting more than  \\n1.5 billion people who are hearing impaired worldwide.\\nEach year we seek ways to make sure our products represent our world. In 2021, we launched Real Tone for Pixel \\u2013 technology to capture and create more accurate images of people of color \\u2013 and in 2022,  \\nwe built on that work by adopting the Monk Skin  \\nTone Scale. This tool, created by Harvard professor  \\nDr. Ellis Monk, offers a broader spectrum of skin tones to inform the technology development process. Beyond Pixel, we started using it to achieve more equitable representation in Search, Google Photos, and more.\\nMonk Scale\\nThe Monk Skin Tone Scale offers a broader range of skin tone shades than is typically used in technology development, helping us build products that better reflect the spectrum of skin tones we see in the world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_counter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.669496414649642,\n        \"min\": 1.0,\n        \"max\": 24.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_gcs_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/temp/img/2021-alphabet-annual-report_page27_mepier.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 94,\n        \"samples\": [\n          [\n            643,\n            468\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 171,\n        \"samples\": [\n          \"The image shows a headshot of a smiling young woman with long black hair. She is wearing an orange shirt and a silver necklace.  The background is blurry and appears to be a home office.  Her expression is friendly and welcoming.  There is no visible text on the image.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 171,\n        \"samples\": [\n          \"214ea9eb75db4141b157000789201af8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "iFlDUxYPbPPu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "55cf0ebb-f820-4c29-dc5d-ab5353ba590d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           video_gcs  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "2  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "3  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "4  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "                                   video_description  chunk_number  \\\n",
              "0  ## Video Transcription and Analysis: Can Gemin...             1   \n",
              "1  analyze complex visual concepts. However, the ...             2   \n",
              "2  o's focus on Gemini's visual comprehension abi...             3   \n",
              "3  giving names and taglines to three unusual emo...             4   \n",
              "4  ncludes the video by showcasing Gemini's uniqu...             5   \n",
              "\n",
              "                                uid  \n",
              "0  bcb310c65f4b4d5489b1de57e5db714f  \n",
              "1  ae10cf80497a4f0083a9d4cc0a09d013  \n",
              "2  3cd19da1300b47059433cefa7b82fa6e  \n",
              "3  30f3e6ba326645668f156d657db978b1  \n",
              "4  37e21f5ac4804aaf831b7ce63efdd21d  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f86a3cca-f920-4100-921e-cade412429c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_gcs</th>\n",
              "      <th>video_description</th>\n",
              "      <th>chunk_number</th>\n",
              "      <th>uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Video Transcription and Analysis: Can Gemin...</td>\n",
              "      <td>1</td>\n",
              "      <td>bcb310c65f4b4d5489b1de57e5db714f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>analyze complex visual concepts. However, the ...</td>\n",
              "      <td>2</td>\n",
              "      <td>ae10cf80497a4f0083a9d4cc0a09d013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>o's focus on Gemini's visual comprehension abi...</td>\n",
              "      <td>3</td>\n",
              "      <td>3cd19da1300b47059433cefa7b82fa6e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>giving names and taglines to three unusual emo...</td>\n",
              "      <td>4</td>\n",
              "      <td>30f3e6ba326645668f156d657db978b1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>ncludes the video by showcasing Gemini's uniqu...</td>\n",
              "      <td>5</td>\n",
              "      <td>37e21f5ac4804aaf831b7ce63efdd21d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f86a3cca-f920-4100-921e-cade412429c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f86a3cca-f920-4100-921e-cade412429c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f86a3cca-f920-4100-921e-cade412429c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f060102-2659-445e-a32e-a607f2693eaf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f060102-2659-445e-a32e-a607f2693eaf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f060102-2659-445e-a32e-a607f2693eaf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "video_metadata_chunk_df",
              "summary": "{\n  \"name\": \"video_metadata_chunk_df\",\n  \"rows\": 188,\n  \"fields\": [\n    {\n      \"column\": \"video_gcs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand new emojis  Testing Gemini.mp4\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Can AI understand your outfit  Testing Gemini.mp4\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Multimodal prompting with a 44-minute movie  Gemini 15 Pro Demo.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 188,\n        \"samples\": [\n          \"otential for automating tasks and producing visually engaging results.\\n\\n**Critical Analysis**:  The segment visualizes Gemini's ability to connect textual data to visual representations. It highlights its potential for streamlining the research process and improving data visualization.\\n\\n**Connections**: This segment reinforces the previous segments by demonstrating the practical application of Gemini's reasoning and data manipulation abilities. It also connects to the next segment by highlightin\",\n          \"he segment emphasizes the technical sophistication of Gemini and its ability to utilize advanced techniques like dynamic programming. However, it oversimplifies the concept of dynamic programming, making it seem more straightforward than it actually is. Additionally, the emphasis on human-AI collaboration is presented as a future ideal, without clear practical examples of successful integration.\\n\\n**Connections:** This segment ties together the previous segments, explaining the reasons behind Gem\",\n          \"questions about the underlying algorithms and the complexity of the process. \\n**Connections**: This segment builds upon the previous one by presenting a more advanced demonstration of Gemini's capabilities. It further highlights the multimodal nature of the model by showing its understanding of visual concepts and its ability to translate them into functional code.\\n\\n**Conclusion**: This video successfully demonstrates the multimodal abilities of Gemini, specifically its capacity to understand an\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 19,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1,\n          6,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 188,\n        \"samples\": [\n          \"a41ef8b970944edcb3ea5ed758ef984a\",\n          \"0f0bf1a5b2ed484da8720ff771bc74a6\",\n          \"d9fb6b0298734f7b9c8ac7acd1a83563\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_metadata_chunk_df.head()"
      ],
      "metadata": {
        "id": "sPR38pVrbPMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d743b31e-5194-4ab6-f856-8d074f25a45a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           audio_gcs  \\\n",
              "0  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "1  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "2  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "3  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "4  gs://mlops-for-genai/multimodal-finanace-qa/da...   \n",
              "\n",
              "                                   audio_description  chunk_number  \\\n",
              "0  ## Alphabet's Second Quarter 2023 Earnings Con...             1   \n",
              "1   segment introduces the call, identifies the s...             2   \n",
              "2  is:**  This segment foreshadows the overarchin...             3   \n",
              "3   tone for the call, emphasizing Alphabet's com...             4   \n",
              "4  iency, as AI is portrayed as a catalyst for bo...             5   \n",
              "\n",
              "                                uid  \n",
              "0  bb7109e8b69f474a83365e0b44264ef1  \n",
              "1  a296b861ede249bba806d6521aee901f  \n",
              "2  0149d44c23bd4cf683d92ac097a4dbb3  \n",
              "3  b98adfda4a354a5fa352d20ca9ba0755  \n",
              "4  7a3d87f7829a4a818f74a07e3c9284df  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcabd3e9-9508-4237-ad9d-5b902cd6ef47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_gcs</th>\n",
              "      <th>audio_description</th>\n",
              "      <th>chunk_number</th>\n",
              "      <th>uid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>## Alphabet's Second Quarter 2023 Earnings Con...</td>\n",
              "      <td>1</td>\n",
              "      <td>bb7109e8b69f474a83365e0b44264ef1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>segment introduces the call, identifies the s...</td>\n",
              "      <td>2</td>\n",
              "      <td>a296b861ede249bba806d6521aee901f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>is:**  This segment foreshadows the overarchin...</td>\n",
              "      <td>3</td>\n",
              "      <td>0149d44c23bd4cf683d92ac097a4dbb3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>tone for the call, emphasizing Alphabet's com...</td>\n",
              "      <td>4</td>\n",
              "      <td>b98adfda4a354a5fa352d20ca9ba0755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gs://mlops-for-genai/multimodal-finanace-qa/da...</td>\n",
              "      <td>iency, as AI is portrayed as a catalyst for bo...</td>\n",
              "      <td>5</td>\n",
              "      <td>7a3d87f7829a4a818f74a07e3c9284df</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcabd3e9-9508-4237-ad9d-5b902cd6ef47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dcabd3e9-9508-4237-ad9d-5b902cd6ef47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dcabd3e9-9508-4237-ad9d-5b902cd6ef47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6577319d-329d-4bba-9fab-653cedbeb37a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6577319d-329d-4bba-9fab-653cedbeb37a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6577319d-329d-4bba-9fab-653cedbeb37a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "audio_metadata_chunk_df",
              "summary": "{\n  \"name\": \"audio_metadata_chunk_df\",\n  \"rows\": 262,\n  \"fields\": [\n    {\n      \"column\": \"audio_gcs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode5.mp3\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode4.mp3\",\n          \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2023 Q2 Earnings Call (128 kbps).mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 262,\n        \"samples\": [\n          \"mic impacts.  \\n* **The Importance of Collaboration and Ethical Considerations:** The speakers highlight the importance of a collective effort and ethical considerations in the development and deployment of AI to ensure equitable and inclusive outcomes.\\n\\nThe overarching message of the audio is that AI holds significant potential for solving global challenges, including climate change, but only if developed and deployed in a way that prioritizes social well-being and equity, and that takes into ac\",\n          \"e constructive and democratic outcomes.\\n* **Synthesize:** This segment builds upon the previous discussion about democracy by emphasizing the need for a more deliberate approach to internet governance, particularly in open societies.\\n\\n**Segment 3: The Role of Persuasion in Democracy (3:34 - 4:45)**\\n\\n* **Summary:** Stewart emphasizes the importance of persuasion in democratic dialogue. He argues that democracy requires a willingness to listen to opposing viewpoints, engage in reasoned argumentati\",\n          \"ct on Research (1:43 - 4:27)**\\n\\n* **Summarize:**  This segment delves into how the advancements in AI are transforming the way genetic diseases are researched. Greka explains that AI allows researchers to look for multiple clues simultaneously, accelerating the process of finding solutions compared to the traditional, one-clue-at-a-time approach.\\n* **Contextualize:** This segment builds upon the previous discussion by illustrating the practical implications of AI in scientific research. Greka us\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 47,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          28,\n          40,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 262,\n        \"samples\": [\n          \"984f2af569c840e790939688d108ada0\",\n          \"3977b7f3bd7b44ae8cd40f8d460b0769\",\n          \"2334cd69d93e4f2e86abda51ee646055\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_jsonl_file(extracted_text_chunk_df, video_metadata_chunk_df, audio_metadata_chunk_df,\n",
        "                      bucket_object, jsonl_file_path):\n",
        "    \"\"\"\n",
        "    Creates a JSONL file containing the combined text, video_description, and audio_description from the given dataframes.\n",
        "\n",
        "    Args:\n",
        "        extracted_text_chunk_df (pandas.DataFrame): The dataframe containing extracted text chunks.\n",
        "        video_metadata_chunk_df (pandas.DataFrame): The dataframe containing video metadata.\n",
        "        audio_metadata_chunk_df (pandas.DataFrame): The dataframe containing audio metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    json_data = []\n",
        "    df_data = []\n",
        "\n",
        "    for index, row in extracted_text_chunk_df.iterrows():\n",
        "        json_data.append({\"content\": row['text']})\n",
        "\n",
        "        df_data.append([row['uid'], \"pdf_text\", row['text']])\n",
        "\n",
        "    for index, row in image_metadata_chunk_df.iterrows():\n",
        "        json_data.append({\"content\": row['image_description']})\n",
        "\n",
        "        df_data.append([row['uid'], \"pdf_images\", row['image_description']])\n",
        "\n",
        "    for index, row in video_metadata_chunk_df.iterrows():\n",
        "        json_data.append({\"content\": row['video_description']})\n",
        "\n",
        "        df_data.append([row['uid'], \"video_description\", row['video_description']])\n",
        "\n",
        "    for index, row in audio_metadata_chunk_df.iterrows():\n",
        "        json_data.append({\"content\": row['audio_description']})\n",
        "\n",
        "        df_data.append([row['uid'], \"audio_description\", row['audio_description']])\n",
        "\n",
        "    # Convert the JSON data to a string\n",
        "    jsonl_data = \"\"\n",
        "    for item in json_data:\n",
        "      jsonl_data += json.dumps(item) + \"\\n\"\n",
        "\n",
        "    # Upload the JSONL data to GCS\n",
        "    blob = bucket.blob(jsonl_file_path+\"/combined_data.jsonl\")\n",
        "    blob.upload_from_string(jsonl_data)\n",
        "    print(f\"File uploaded to GCS: {blob.public_url}\")\n",
        "\n",
        "    gcs_path_jsonl_data = f\"gs://{bucket.name}/{blob.name}\"\n",
        "\n",
        "    return pd.DataFrame(json_data), pd.DataFrame(df_data, columns=['uid','type', 'content']), gcs_path_jsonl_data\n",
        "\n"
      ],
      "metadata": {
        "id": "LaN7sx2WNtvT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_db_emb, index_db, gcs_path_jsonl_data = create_jsonl_file(extracted_text_chunk_df, video_metadata_chunk_df, audio_metadata_chunk_df,\n",
        "                                          bucket,embedding_input_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2BsxFg832KO",
        "outputId": "3495c9b9-31f3-4114-d04a-aba83181390f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File uploaded to GCS: https://storage.googleapis.com/mlops-for-genai/multimodal-finanace-qa/data/embeddings/combined_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_db.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OKeswX-ctBqC",
        "outputId": "c248c4c7-c81e-491a-bed8-5661127920ef"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                uid      type  \\\n",
              "0  91eb9e70cc47499ea0e66c7bac787471  pdf_text   \n",
              "1  9e1cbaf288584e13b5cdd2ef505da1fb  pdf_text   \n",
              "2  6b2aa4129b1649e9aeadea99037dde31  pdf_text   \n",
              "3  96c064d349d441a7bdca3f95b839ebe8  pdf_text   \n",
              "4  632d6d7b82be456b8df44fd7dd6dda1e  pdf_text   \n",
              "\n",
              "                                             content  \n",
              "0  Additionally, CoSAI will collaborate with orga...  \n",
              "1  ll to help organizations securely implement, t...  \n",
              "2  \\nSafety & Security  AI8/13/24, 8:09 PM Google...  \n",
              "3  1.5 Pro can now follow increasingly complex an...  \n",
              "4  .5 Pro can now reason\\nacross image and audio ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ee6c705-a363-4fd0-a029-687a2d38efb4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91eb9e70cc47499ea0e66c7bac787471</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>Additionally, CoSAI will collaborate with orga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9e1cbaf288584e13b5cdd2ef505da1fb</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>ll to help organizations securely implement, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6b2aa4129b1649e9aeadea99037dde31</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>\\nSafety &amp; Security  AI8/13/24, 8:09 PM Google...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96c064d349d441a7bdca3f95b839ebe8</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>1.5 Pro can now follow increasingly complex an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>632d6d7b82be456b8df44fd7dd6dda1e</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>.5 Pro can now reason\\nacross image and audio ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee6c705-a363-4fd0-a029-687a2d38efb4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ee6c705-a363-4fd0-a029-687a2d38efb4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ee6c705-a363-4fd0-a029-687a2d38efb4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebb05439-7191-4293-95ec-82128bb1ea00\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebb05439-7191-4293-95ec-82128bb1ea00')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebb05439-7191-4293-95ec-82128bb1ea00 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "index_db",
              "summary": "{\n  \"name\": \"index_db\",\n  \"rows\": 10690,\n  \"fields\": [\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10690,\n        \"samples\": [\n          \"db585856366546c1a2db67fa2ff51bf5\",\n          \"dad9466c1d4e4bcbb019e623b2115031\",\n          \"2a063bfa2fde48c99d58cc3baca54570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pdf_images\",\n          \"audio_description\",\n          \"pdf_text\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10226,\n        \"samples\": [\n          \"etired  (in millions):\\nYear Ended December 31, 2021 Year Ended December 31, 2022\\nShares Amount Shares Amount\\nClass A share repurchases 24$ 3,399 61$ 6,719 \\nClass C share repurchases 383  46,875 469  52,577 \\nTotal share repurchases 407 $ 50,274 530 $ 59,296 \\nClass A and Class C shares are repurchased in a manner deemed in the best interest of the company and its \\nstockholders, taking into account the economic cost and prevailing market conditions, including the relative trading \\nprices and volume\",\n          \"dvance   \\nfor   the   color.     \\n  \\nSundar   Pichai,   CEO   Alphabet   and   Google:    Eric,   great   question.   You're   right   in   the   fact   that   AI   \\nand   ML   itself   is   the   broader,   deeper   investments   we   are   driving,   and   we   are   using   it   across   our   \\nproduct   portfolio.   \\n7   \",\n          \"2015\\n4.06 Joinder Agreement, dated December 31, \\n2021, among the Registrant, Sergey Brin and \\ncertain of his affiliates  Annual Report on Form 10-K \\n(File No. 001-37580)February 2, 2022Exhibit\\nNumber DescriptionIncorporated by reference herein\\nForm DateTable of Contents Alphabet Inc.\\n86\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_db.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2kDMtJgA7e8",
        "outputId": "362aaef5-c3ab-406b-ab02-64f6d6e14a27"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10690, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_path_jsonl_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__BkG9tD-2le",
        "outputId": "943e15f3-ff5e-485a-e3aa-f00d20ecdfd9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gs://mlops-for-genai/multimodal-finanace-qa/data/embeddings/combined_data.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://cloud.google.com/bigquery/docs/generate-text-tutorial#grant-permissions"
      ],
      "metadata": {
        "id": "x7ndI97zT9Eg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "from vertexai.preview import language_models\n",
        "\n",
        "input_uri = (\n",
        "    gcs_path_jsonl_data\n",
        ")\n",
        "# Format: `gs://BUCKET_NAME/DIRECTORY/` or `bq://project_name.llm_dataset`\n",
        "output_uri = \"gs://mlops-for-genai/multimodal-finanace-qa/data/embeddings/combined_data_output/\"\n",
        "\n",
        "textembedding_model = language_models.TextEmbeddingModel.from_pretrained(\n",
        "    \"textembedding-gecko@003\"\n",
        ")\n",
        "\n",
        "batch_prediction_job = textembedding_model.batch_predict(\n",
        "    dataset=[input_uri],\n",
        "    destination_uri_prefix=output_uri,\n",
        ")\n",
        "print(batch_prediction_job.display_name)\n",
        "print(batch_prediction_job.resource_name)\n",
        "print(batch_prediction_job.state)"
      ],
      "metadata": {
        "id": "lxSmTVKLbPFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2148a507-41dc-4a8b-bf1e-4776ef9cb16c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680\n",
            "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
            "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680')\n",
            "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8041471906865479680?project=1054577272268\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680 current state:\n",
            "JobState.JOB_STATE_QUEUED\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680 current state:\n",
            "JobState.JOB_STATE_QUEUED\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680 current state:\n",
            "JobState.JOB_STATE_QUEUED\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680 current state:\n",
            "JobState.JOB_STATE_QUEUED\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680 current state:\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob run completed. Resource name: projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob 2024-09-12 07:50:56.769157\n",
            "projects/1054577272268/locations/us-central1/batchPredictionJobs/8041471906865479680\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "CPU times: user 961 ms, sys: 130 ms, total: 1.09 s\n",
            "Wall time: 1min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jsonl_from_gcs(bucket, file_path):\n",
        "    \"\"\"Loads a JSONL file from a GCS bucket and converts it into a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        bucket_name (str): The name of the GCS bucket.\n",
        "        file_path (str): The path to the JSONL file within the bucket.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The DataFrame created from the JSONL data.\n",
        "    \"\"\"\n",
        "\n",
        "    # storage_client = storage.Client()\n",
        "    # bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_path)\n",
        "\n",
        "    with blob.open('rb') as f:\n",
        "        data = []\n",
        "        for line in f:\n",
        "            instance = json.loads(line)\n",
        "            content = instance['instance']['content']\n",
        "            predictions = instance['predictions'][0]['embeddings']['values']\n",
        "            data.append({'content': content, 'predictions': predictions})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "9t_Rcp8kD-zA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "file_path = 'multimodal-finanace-qa/data/embeddings/combined_data_output/prediction-model-2024-09-12T07:50:57.319163Z/000000000000.jsonl'\n",
        "embedding_df = load_jsonl_from_gcs(bucket, file_path)"
      ],
      "metadata": {
        "id": "vY6U7sskbPCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c64fab-c25f-40b0-dca5-b824594ae9c8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 58s, sys: 1.12 s, total: 1min 59s\n",
            "Wall time: 2min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MXzpSzl2_7w9",
        "outputId": "1c63ac07-748f-427a-f177-302e00d3b2f2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  \\\n",
              "0  \u0003\u0006\u0015\u0010\u0017\u0003DKNNKQP\u000e\u0003NCTIGN[\u0003TGUWNVKPI\u0003HTQO\u0003CP\u0003\u0013\u0013\u0007\u0003K...   \n",
              "1  \u0003\\n6JGUG\u0003RCTVPGTU\u0003OC[\u0003PQV\u0003EQPVKPWG\u0003VQ\u0003FQ\u0003DWUKP...   \n",
              "2  \u0003\\nDCPFYKFVJ\u0003VQ\u0003YQTM\u0003GHHGEVKXGN[\u0010\u0003%WTTGPVN[\u000e\u0003V...   \n",
              "3  \u0003\\nUKIPKƒECPV\u0003KPHNWGPEG\u0003QXGT\u0003CNN\u0003OCVVGTU\u0003TGSWK...   \n",
              "4  \u0003\u0012\u0012\u0013\u000f\u0015\u0019\u0017\u001a\u0012\n",
              "\u00031EVQDGT\u0003\u0014\u000e\u0003\u0014\u0012\u0013\u0017\\n\u0015\u0010\u0012\u0014 #OGPFGF\u0003CPF\u0003...   \n",
              "\n",
              "                                         predictions  \n",
              "0  [0.020302558317780495, 0.004051088821142912, -...  \n",
              "1  [0.023772958666086197, -0.025965938344597816, ...  \n",
              "2  [-0.0009582438506186008, -0.012345915660262108...  \n",
              "3  [0.012308558449149132, -0.02015942893922329, -...  \n",
              "4  [-0.021374214440584183, -0.0028167085256427526...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b033c0f3-9e89-4907-b6d0-1538fbc69a2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\u0003\u0006\u0015\u0010\u0017\u0003DKNNKQP\u000e\u0003NCTIGN[\u0003TGUWNVKPI\u0003HTQO\u0003CP\u0003\u0013\u0013\u0007\u0003K...</td>\n",
              "      <td>[0.020302558317780495, 0.004051088821142912, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\u0003\\n6JGUG\u0003RCTVPGTU\u0003OC[\u0003PQV\u0003EQPVKPWG\u0003VQ\u0003FQ\u0003DWUKP...</td>\n",
              "      <td>[0.023772958666086197, -0.025965938344597816, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\u0003\\nDCPFYKFVJ\u0003VQ\u0003YQTM\u0003GHHGEVKXGN[\u0010\u0003%WTTGPVN[\u000e\u0003V...</td>\n",
              "      <td>[-0.0009582438506186008, -0.012345915660262108...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\u0003\\nUKIPKƒECPV\u0003KPHNWGPEG\u0003QXGT\u0003CNN\u0003OCVVGTU\u0003TGSWK...</td>\n",
              "      <td>[0.012308558449149132, -0.02015942893922329, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\u0003\u0012\u0012\u0013\u000f\u0015\u0019\u0017\u001a\u0012\u000b\u00031EVQDGT\u0003\u0014\u000e\u0003\u0014\u0012\u0013\u0017\\n\u0015\u0010\u0012\u0014 #OGPFGF\u0003CPF\u0003...</td>\n",
              "      <td>[-0.021374214440584183, -0.0028167085256427526...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b033c0f3-9e89-4907-b6d0-1538fbc69a2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b033c0f3-9e89-4907-b6d0-1538fbc69a2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b033c0f3-9e89-4907-b6d0-1538fbc69a2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35e1bc3f-d979-4a69-8537-f1f329ea7bf6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35e1bc3f-d979-4a69-8537-f1f329ea7bf6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35e1bc3f-d979-4a69-8537-f1f329ea7bf6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedding_df",
              "summary": "{\n  \"name\": \"embedding_df\",\n  \"rows\": 10690,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10226,\n        \"samples\": [\n          \"s and across various verticals and \\nchannels.\\nGoogle Other\\nGoogle other revenues are comprised of the following:\\n\\u2022Google Play, which includes sales of apps and in-app purchases;\\n\\u2022hardware, which includes sales of Fitbit wearable devices, Google Nest home products, and Pixel devices;\\n\\u2022YouTube non-advertising, which includes subscription revenues from services such as YouTube Premium \\nand YouTube TV; and\\n\\u2022other products and services.\\nFluctuations in our Google other revenues have been and may cont\",\n          \"9  and 2020  were related to derivative assets which are allowed to be net settled \\nagainst derivative liabilities in accordance with our master netting agreements.\\nNote 4.    Leases  \\nWe have entered into operating and finance lease agreements primarily for data centers, land and offices \\nthroughout the world with lease periods expiring between 2021  and 2063 . \\nComponents of operating lease expense were as follows (in millions):\\nYear Ended December 31,\\n2019 2020\\nOperating lease cost $ 1,820 $ \",\n          \"s of March 31, 2022\\n Less than 12 Months 12 Months or Greater Total\\n Fair ValueUnrealized\\nLoss Fair ValueUnrealized\\nLoss Fair ValueUnrealized\\nLoss\\nGovernment bonds $ 37,948 $ (1,203) $ 3,909 $ (162) $ 41,857 $ (1,365) \\nCorporate debt securities  27,403  (879)  2,572  (164)  29,975  (1,043) \\nMortgage-backed and asset-backed \\nsecurities  15,415  (532)  1,101  (62)  16,516  (594) \\nTotal $ 80,766 $ (2,614) $ 7,582 $ (388) $ 88,348 $ (3,002) \\nDuring the  three months ended March 31, 2021  and 2022 , \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of embedding_df: \", embedding_df.shape)\n",
        "print(\"Size of index_db: \", index_db.shape)"
      ],
      "metadata": {
        "id": "IfkEjoWabO-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed29314a-8c57-4e0a-9a74-e78cb7be023d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of embedding_df:  (10690, 2)\n",
            "Size of index_db:  (10690, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining embedding_df with the index_df\n",
        "index_db_final = index_db.merge(embedding_df, on='content', how='left')"
      ],
      "metadata": {
        "id": "8CJy3UDCCJoJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_db_final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M2HJPRClCUG_",
        "outputId": "3e7d5459-49e1-4af3-b4f3-9b97e4db4173"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                uid      type  \\\n",
              "0  91eb9e70cc47499ea0e66c7bac787471  pdf_text   \n",
              "1  9e1cbaf288584e13b5cdd2ef505da1fb  pdf_text   \n",
              "2  6b2aa4129b1649e9aeadea99037dde31  pdf_text   \n",
              "3  96c064d349d441a7bdca3f95b839ebe8  pdf_text   \n",
              "4  632d6d7b82be456b8df44fd7dd6dda1e  pdf_text   \n",
              "\n",
              "                                             content  \\\n",
              "0  Additionally, CoSAI will collaborate with orga...   \n",
              "1  ll to help organizations securely implement, t...   \n",
              "2  \\nSafety & Security  AI8/13/24, 8:09 PM Google...   \n",
              "3  1.5 Pro can now follow increasingly complex an...   \n",
              "4  .5 Pro can now reason\\nacross image and audio ...   \n",
              "\n",
              "                                         predictions  \n",
              "0  [-0.0019601150415837765, -0.029520384967327118...  \n",
              "1  [0.027416100725531578, -0.02166818082332611, -...  \n",
              "2  [0.01608710177242756, -0.0351220928132534, -0....  \n",
              "3  [-0.017015989869832993, -0.02816266193985939, ...  \n",
              "4  [0.003014838322997093, -0.018015660345554352, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddb3783d-3cb7-474c-bf2a-c3e039810315\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>91eb9e70cc47499ea0e66c7bac787471</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>Additionally, CoSAI will collaborate with orga...</td>\n",
              "      <td>[-0.0019601150415837765, -0.029520384967327118...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9e1cbaf288584e13b5cdd2ef505da1fb</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>ll to help organizations securely implement, t...</td>\n",
              "      <td>[0.027416100725531578, -0.02166818082332611, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6b2aa4129b1649e9aeadea99037dde31</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>\\nSafety &amp; Security  AI8/13/24, 8:09 PM Google...</td>\n",
              "      <td>[0.01608710177242756, -0.0351220928132534, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96c064d349d441a7bdca3f95b839ebe8</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>1.5 Pro can now follow increasingly complex an...</td>\n",
              "      <td>[-0.017015989869832993, -0.02816266193985939, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>632d6d7b82be456b8df44fd7dd6dda1e</td>\n",
              "      <td>pdf_text</td>\n",
              "      <td>.5 Pro can now reason\\nacross image and audio ...</td>\n",
              "      <td>[0.003014838322997093, -0.018015660345554352, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddb3783d-3cb7-474c-bf2a-c3e039810315')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddb3783d-3cb7-474c-bf2a-c3e039810315 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddb3783d-3cb7-474c-bf2a-c3e039810315');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23fe8c9a-e67f-46d2-85f9-2c035389dc25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23fe8c9a-e67f-46d2-85f9-2c035389dc25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23fe8c9a-e67f-46d2-85f9-2c035389dc25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "index_db_final",
              "summary": "{\n  \"name\": \"index_db_final\",\n  \"rows\": 14898,\n  \"fields\": [\n    {\n      \"column\": \"uid\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10690,\n        \"samples\": [\n          \"db585856366546c1a2db67fa2ff51bf5\",\n          \"dad9466c1d4e4bcbb019e623b2115031\",\n          \"2a063bfa2fde48c99d58cc3baca54570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pdf_images\",\n          \"audio_description\",\n          \"pdf_text\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10226,\n        \"samples\": [\n          \"etired  (in millions):\\nYear Ended December 31, 2021 Year Ended December 31, 2022\\nShares Amount Shares Amount\\nClass A share repurchases 24$ 3,399 61$ 6,719 \\nClass C share repurchases 383  46,875 469  52,577 \\nTotal share repurchases 407 $ 50,274 530 $ 59,296 \\nClass A and Class C shares are repurchased in a manner deemed in the best interest of the company and its \\nstockholders, taking into account the economic cost and prevailing market conditions, including the relative trading \\nprices and volume\",\n          \"dvance   \\nfor   the   color.     \\n  \\nSundar   Pichai,   CEO   Alphabet   and   Google:    Eric,   great   question.   You're   right   in   the   fact   that   AI   \\nand   ML   itself   is   the   broader,   deeper   investments   we   are   driving,   and   we   are   using   it   across   our   \\nproduct   portfolio.   \\n7   \",\n          \"2015\\n4.06 Joinder Agreement, dated December 31, \\n2021, among the Registrant, Sergey Brin and \\ncertain of his affiliates  Annual Report on Form 10-K \\n(File No. 001-37580)February 2, 2022Exhibit\\nNumber DescriptionIncorporated by reference herein\\nForm DateTable of Contents Alphabet Inc.\\n86\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predictions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to test if mapping is done right.\n",
        "test_index = 5000\n",
        "print(\"*****original emb in embedding_db: *****\\n\", embedding_df.iloc[test_index]['predictions'][:5])\n",
        "print(\"\\n*****emb in index_db****\\n\", index_db_final[index_db_final['content']==embedding_df.iloc[test_index]['content']]['predictions'].values[0][:5])\n",
        "print(\"\\n*****Original content in embedding_db *****\", embedding_df.iloc[test_index]['content'])\n",
        "print(\"\\n*****content in index_db*****\", index_db_final[index_db_final['content']==embedding_df.iloc[test_index]['content']]['content'].values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aAG1Og4DI4Y",
        "outputId": "0ad91c7c-1379-45e9-da69-b836defa66c7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****original emb in embedding_db: *****\n",
            " [0.03795702010393143, -0.03185933455824852, 0.01030017901211977, 0.035032641142606735, 0.05800672248005867]\n",
            "\n",
            "*****emb in index_db****\n",
            " [0.03795702010393143, -0.03185933455824852, 0.01030017901211977, 0.035032641142606735, 0.05800672248005867]\n",
            "\n",
            "*****Original content in embedding_db ***** cost of revenues, research and development (R&D) expenses, sales and marketing \n",
            "expenses, and general and administrative expenses may increase in amount and/or may increase as a \n",
            "percentage of revenues and may be affected by a number of factors;\n",
            "•estimates of our future compensation expenses;\n",
            "•our expectation that our other income (expense), net (OI&E), will fluctuate in the future, as it is largely \n",
            "driven by market dynamics;\n",
            "•fluctuations in our effective tax rate;\n",
            "•seasonal fluctuations in in\n",
            "\n",
            "*****content in index_db***** cost of revenues, research and development (R&D) expenses, sales and marketing \n",
            "expenses, and general and administrative expenses may increase in amount and/or may increase as a \n",
            "percentage of revenues and may be affected by a number of factors;\n",
            "•estimates of our future compensation expenses;\n",
            "•our expectation that our other income (expense), net (OI&E), will fluctuate in the future, as it is largely \n",
            "driven by market dynamics;\n",
            "•fluctuations in our effective tax rate;\n",
            "•seasonal fluctuations in in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_db_final.value_counts('type')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "I8qKJTOGDf2w",
        "outputId": "dc65e2fb-cae6-4568-bb25-a97a4d31ca92"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type\n",
              "pdf_text             14277\n",
              "audio_description      262\n",
              "video_description      188\n",
              "pdf_images             171\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pdf_text</th>\n",
              "      <td>14277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>audio_description</th>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>video_description</th>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pdf_images</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert DataFrame to CSV string\n",
        "# csv_string = index_db_final.to_csv()\n",
        "\n",
        "# # Create a StringIO object to simulate a file-like object\n",
        "# string_io = io.StringIO(csv_string)"
      ],
      "metadata": {
        "id": "ab2khz7GGwzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Upload the index_db_final data to GCS\n",
        "# blob = bucket.blob(\"multimodal-finanace-qa/data/embeddings\"+\"/index_db_final.csv\")\n",
        "# blob.upload_from_string(index_db_final)\n",
        "# print(f\"File uploaded to GCS: {blob.public_url}\")"
      ],
      "metadata": {
        "id": "qOouJKqmGOKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}